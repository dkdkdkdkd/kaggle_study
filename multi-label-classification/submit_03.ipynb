{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.style.use(\"ggplot\")\n",
    "import lightgbm as lgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../Data/multi-label-classification-data/train_process.csv')\n",
    "test_df = pd.read_csv('../Data/multi-label-classification-data/test.csv')\n",
    "label_df = pd.read_csv('../Data/multi-label-classification-data/label.csv')\n",
    "submission = pd.read_csv('../Data/multi-label-classification-data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['id','FpDensityMorgan1', 'FpDensityMorgan2','FpDensityMorgan3'], axis=1)\n",
    "test_df = test_df.drop(['id','FpDensityMorgan1', 'FpDensityMorgan2','FpDensityMorgan3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 검증 데이터 분할\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_df, label_df,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = label_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터\n",
    "params={\"num_leaves\":300,\n",
    "       \"max_bin\":450,\n",
    "       \"feature_fraction\":0.52,\n",
    "       \"bagging_fraction\":0.52,\n",
    "       \"objective\":\"binary\",\n",
    "       \"learning_rate\":0.05,\n",
    "       \"boosting_type\":\"gbdt\",\n",
    "       \"metric\":\"auc\"\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:00,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 6955, number of negative: 3431\n",
      "[LightGBM] [Info] Total Bins 8531\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669651 -> initscore=0.706609\n",
      "[LightGBM] [Info] Start training from score 0.706609\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's auc: 0.941193\tvalid_1's auc: 0.686449\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 8300, number of negative: 2086\n",
      "[LightGBM] [Info] Total Bins 8531\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.799153 -> initscore=1.381007\n",
      "[LightGBM] [Info] Start training from score 1.381007\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:00<00:00,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.963821\tvalid_1's auc: 0.54863\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 3246, number of negative: 7140\n",
      "[LightGBM] [Info] Total Bins 8531\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312536 -> initscore=-0.788289\n",
      "[LightGBM] [Info] Start training from score -0.788289\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's auc: 0.969636\tvalid_1's auc: 0.639309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:00<00:00,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 2916, number of negative: 7470\n",
      "[LightGBM] [Info] Total Bins 8531\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.280763 -> initscore=-0.940682\n",
      "[LightGBM] [Info] Start training from score -0.940682\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's auc: 0.95729\tvalid_1's auc: 0.664753\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 1511, number of negative: 8875\n",
      "[LightGBM] [Info] Total Bins 8531\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.145484 -> initscore=-1.770467\n",
      "[LightGBM] [Info] Start training from score -1.770467\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's auc: 0.983824\tvalid_1's auc: 0.671605\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 1549, number of negative: 8837\n",
      "[LightGBM] [Info] Total Bins 8531\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.149143 -> initscore=-1.741338\n",
      "[LightGBM] [Info] Start training from score -1.741338\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's auc: 0.953061\tvalid_1's auc: 0.57319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "\n",
    "models = []\n",
    "for  i in tqdm(range(y_train.shape[1])):\n",
    "    \n",
    "    train = lgbm.Dataset(x_train, y_train.iloc[:,i])\n",
    "    test = lgbm.Dataset(x_test, y_test.iloc[:,i])\n",
    "    model = lgbm.train(params=params, train_set=train, valid_sets=[train, test], num_boost_round=1000, early_stopping_rounds=10, verbose_eval=100)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EC1</th>\n",
       "      <th>EC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14838</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14839</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14840</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14841</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14842</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9888</th>\n",
       "      <td>24726</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9889</th>\n",
       "      <td>24727</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9890</th>\n",
       "      <td>24728</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9891</th>\n",
       "      <td>24729</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>24730</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9893 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  EC1  EC2\n",
       "0     14838  0.5  0.5\n",
       "1     14839  0.5  0.5\n",
       "2     14840  0.5  0.5\n",
       "3     14841  0.5  0.5\n",
       "4     14842  0.5  0.5\n",
       "...     ...  ...  ...\n",
       "9888  24726  0.5  0.5\n",
       "9889  24727  0.5  0.5\n",
       "9890  24728  0.5  0.5\n",
       "9891  24729  0.5  0.5\n",
       "9892  24730  0.5  0.5\n",
       "\n",
       "[9893 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission[['id']]\n",
    "\n",
    "ec1 = pd.DataFrame(models[0].predict(test_df), columns=['EC1'])\n",
    "ec2 = pd.DataFrame(models[1].predict(test_df), columns=['EC2'])\n",
    "submission = pd.concat([submission, ec1, ec2], axis=1)\n",
    "submission.to_csv('submit_03.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
