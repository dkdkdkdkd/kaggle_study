{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optuna 튜닝\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc\n",
    "plt.style.use(\"ggplot\")\n",
    "import lightgbm as lgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../Data/multi-label-classification-data/train_process.csv')\n",
    "test_df = pd.read_csv('../Data/multi-label-classification-data/test.csv')\n",
    "label_df = pd.read_csv('../Data/multi-label-classification-data/label.csv')\n",
    "submission = pd.read_csv('../Data/multi-label-classification-data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['id','FpDensityMorgan1', 'FpDensityMorgan2','FpDensityMorgan3'], axis=1)\n",
    "test_df = test_df.drop(['id','FpDensityMorgan1', 'FpDensityMorgan2','FpDensityMorgan3'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skew_feature = ['BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3v', 'Chi4n',\n",
    "#        'EState_VSA1', 'EState_VSA2', 'ExactMolWt', 'FpDensityMorgan1',\n",
    "#        'FpDensityMorgan2', 'FpDensityMorgan3',\n",
    "#        'HeavyAtomMolWt', 'Kappa3', \n",
    "#        'NumHeteroatoms', 'PEOE_VSA10', 'PEOE_VSA14', 'PEOE_VSA6', 'PEOE_VSA7',\n",
    "#        'PEOE_VSA8', 'SMR_VSA10', 'SMR_VSA5', 'SlogP_VSA3', 'VSA_EState9',\n",
    "#        ]\n",
    "skew_feature = [ 'Kappa3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "for col in skew_feature:\n",
    "    train_df[col] = np.log1p(train_df[col])\n",
    "    test_df[col] = np.log1p(test_df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 검증 데이터 분할\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_df, label_df,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = label_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna 사용\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "train = lgbm.Dataset(x_train, y_train.iloc[:,0])\n",
    "test = lgbm.Dataset(x_test, y_test.iloc[:,0])\n",
    "def objective(trial : Trial):\n",
    "    params = {\n",
    "        'boosting_type' : 'gbdt',\n",
    "        \"n_estimators\" : 10000,\n",
    "#         'fold_size':trial.suggest_int('fold_size', 4, 16),\n",
    "        'max_depth':trial.suggest_int('max_depth', 4, 16),\n",
    "        'random_state': 722,\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 10.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 8, 25),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.8, 1.0),\n",
    "        'subsample_freq': trial.suggest_int('subsample_freq', 1, 8),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 16, 64),\n",
    "        'learning_rate': 0.05,\n",
    "        \"metric\":\"auc\",\n",
    "        #\"objective\":\"binary\",\n",
    "    }\n",
    "    \n",
    "    model = lgbm.train(params=params, train_set=train, valid_sets=[train, test], num_boost_round=500, early_stopping_rounds=10, verbose_eval=100)\n",
    "    preds = model.predict(x_test)\n",
    "    print(preds)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test['EC1'], preds, pos_label=1)\n",
    "    \n",
    "    score = auc(fpr, tpr)\n",
    "    \n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:23,629]\u001b[0m Trial 0 finished with value: 0.700529921422621 and parameters: {'max_depth': 7, 'reg_alpha': 0.09960428243405861, 'reg_lambda': 0.22715815282277732, 'num_leaves': 22, 'colsample_bytree': 0.8722546488685065, 'subsample': 0.9395441544347632, 'subsample_freq': 5, 'min_child_samples': 48}. Best is trial 0 with value: 0.700529921422621.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:23,662]\u001b[0m Trial 1 finished with value: 0.7016348625117608 and parameters: {'max_depth': 8, 'reg_alpha': 8.009195599083838e-06, 'reg_lambda': 0.3136508069995879, 'num_leaves': 16, 'colsample_bytree': 0.7149637266915307, 'subsample': 0.8551792702498177, 'subsample_freq': 7, 'min_child_samples': 53}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:23,706]\u001b[0m Trial 2 finished with value: 0.6991516162933155 and parameters: {'max_depth': 13, 'reg_alpha': 8.995666728399347e-08, 'reg_lambda': 0.00015767813046958708, 'num_leaves': 17, 'colsample_bytree': 0.8427785559875671, 'subsample': 0.9636263854903898, 'subsample_freq': 3, 'min_child_samples': 37}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:23,736]\u001b[0m Trial 3 finished with value: 0.6980617989218723 and parameters: {'max_depth': 11, 'reg_alpha': 0.010807355048757452, 'reg_lambda': 0.1327045007581285, 'num_leaves': 9, 'colsample_bytree': 0.5787029164072051, 'subsample': 0.9764629793546828, 'subsample_freq': 8, 'min_child_samples': 36}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:23,769]\u001b[0m Trial 4 finished with value: 0.6995128798355814 and parameters: {'max_depth': 12, 'reg_alpha': 2.235300133445844e-08, 'reg_lambda': 1.233163831866334e-07, 'num_leaves': 19, 'colsample_bytree': 0.7587841849783804, 'subsample': 0.980129716520491, 'subsample_freq': 7, 'min_child_samples': 52}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's auc: 0.753825\tvalid_1's auc: 0.70053\n",
      "[0.80800271 0.50782037 0.73373739 ... 0.82173696 0.75985569 0.81448794]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's auc: 0.729707\tvalid_1's auc: 0.701635\n",
      "[0.78525428 0.55247812 0.73830851 ... 0.78066032 0.75125159 0.79058419]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.740277\tvalid_1's auc: 0.699152\n",
      "[0.7985441  0.57045419 0.7691467  ... 0.80684863 0.75399507 0.80602956]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's auc: 0.722175\tvalid_1's auc: 0.698062\n",
      "[0.78977754 0.5384109  0.74202995 ... 0.79267604 0.75378261 0.79169757]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's auc: 0.730942\tvalid_1's auc: 0.699513\n",
      "[0.76816372 0.58981809 0.71958643 ... 0.77397098 0.73834984 0.77265158]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-07 14:02:23,817]\u001b[0m Trial 5 finished with value: 0.6969952925438707 and parameters: {'max_depth': 5, 'reg_alpha': 0.9582230982167326, 'reg_lambda': 7.152564688062882e-05, 'num_leaves': 15, 'colsample_bytree': 0.7684572786692424, 'subsample': 0.8240601373440103, 'subsample_freq': 3, 'min_child_samples': 45}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:23,884]\u001b[0m Trial 6 finished with value: 0.6983253837160088 and parameters: {'max_depth': 12, 'reg_alpha': 0.1770251852793314, 'reg_lambda': 1.4132868948701122e-06, 'num_leaves': 25, 'colsample_bytree': 0.8034341752822411, 'subsample': 0.8616821527036511, 'subsample_freq': 6, 'min_child_samples': 18}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:23,919]\u001b[0m Trial 7 finished with value: 0.6985155104527633 and parameters: {'max_depth': 8, 'reg_alpha': 0.009609949176170886, 'reg_lambda': 0.4718499662740968, 'num_leaves': 11, 'colsample_bytree': 0.6664102355818371, 'subsample': 0.9558919321700787, 'subsample_freq': 8, 'min_child_samples': 18}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:23,948]\u001b[0m Trial 8 finished with value: 0.7009080143650301 and parameters: {'max_depth': 6, 'reg_alpha': 0.007348426638014264, 'reg_lambda': 0.00016053839158544173, 'num_leaves': 15, 'colsample_bytree': 0.6644666660811427, 'subsample': 0.9675645331856831, 'subsample_freq': 5, 'min_child_samples': 24}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:23,989]\u001b[0m Trial 9 finished with value: 0.6997372339334379 and parameters: {'max_depth': 9, 'reg_alpha': 0.0022839763916021345, 'reg_lambda': 0.04210442288239182, 'num_leaves': 14, 'colsample_bytree': 0.787007567813389, 'subsample': 0.9686822941160129, 'subsample_freq': 6, 'min_child_samples': 45}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's auc: 0.74001\tvalid_1's auc: 0.696995\n",
      "[0.83109623 0.59086921 0.7366271  ... 0.82702856 0.7511636  0.83109623]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.736661\tvalid_1's auc: 0.698325\n",
      "[0.7612349  0.57316165 0.73665119 ... 0.76163947 0.72925692 0.76413778]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's auc: 0.725483\tvalid_1's auc: 0.698516\n",
      "[0.79013955 0.55282744 0.77135012 ... 0.79172179 0.76708873 0.79263928]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's auc: 0.727341\tvalid_1's auc: 0.700908\n",
      "[0.76858824 0.56802707 0.75202594 ... 0.77317512 0.73760681 0.77123941]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.733092\tvalid_1's auc: 0.699737\n",
      "[0.79532432 0.55972428 0.75309218 ... 0.80656146 0.76224555 0.80013076]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,037]\u001b[0m Trial 10 finished with value: 0.6992794287646742 and parameters: {'max_depth': 16, 'reg_alpha': 8.526243106586949e-06, 'reg_lambda': 6.199428804610007, 'num_leaves': 20, 'colsample_bytree': 0.963773366962577, 'subsample': 0.8909986376375555, 'subsample_freq': 2, 'min_child_samples': 64}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,076]\u001b[0m Trial 11 finished with value: 0.6992845458120152 and parameters: {'max_depth': 4, 'reg_alpha': 3.541642528597936e-05, 'reg_lambda': 0.003208755026270289, 'num_leaves': 12, 'colsample_bytree': 0.6286545154288832, 'subsample': 0.8131855777755064, 'subsample_freq': 5, 'min_child_samples': 26}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,115]\u001b[0m Trial 12 finished with value: 0.6996396688974719 and parameters: {'max_depth': 6, 'reg_alpha': 4.096061240333811e-06, 'reg_lambda': 6.151063444514766e-06, 'num_leaves': 17, 'colsample_bytree': 0.5060400848744797, 'subsample': 0.8542227696548522, 'subsample_freq': 4, 'min_child_samples': 61}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,151]\u001b[0m Trial 13 finished with value: 0.7000912198972633 and parameters: {'max_depth': 9, 'reg_alpha': 0.00020721803368636276, 'reg_lambda': 0.004096959969326197, 'num_leaves': 14, 'colsample_bytree': 0.6767218715249547, 'subsample': 0.9167400298128621, 'subsample_freq': 7, 'min_child_samples': 28}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,183]\u001b[0m Trial 14 finished with value: 0.6970074597453256 and parameters: {'max_depth': 4, 'reg_alpha': 1.0063760347398978e-06, 'reg_lambda': 0.0027284542608511657, 'num_leaves': 8, 'colsample_bytree': 0.538614023706078, 'subsample': 0.8854331095454284, 'subsample_freq': 6, 'min_child_samples': 56}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,214]\u001b[0m Trial 15 finished with value: 0.69879763032949 and parameters: {'max_depth': 7, 'reg_alpha': 0.00025183906553781255, 'reg_lambda': 7.647640129446119, 'num_leaves': 19, 'colsample_bytree': 0.7007328204841066, 'subsample': 0.844234907784625, 'subsample_freq': 4, 'min_child_samples': 28}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.738395\tvalid_1's auc: 0.699279\n",
      "[0.7916598  0.57951971 0.76675366 ... 0.7842971  0.76348068 0.79437548]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.73123\tvalid_1's auc: 0.699285\n",
      "[0.80600664 0.55153358 0.73515519 ... 0.82136504 0.75785553 0.8091915 ]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's auc: 0.734901\tvalid_1's auc: 0.69964\n",
      "[0.79841323 0.54734689 0.75938487 ... 0.80232835 0.74117793 0.80153604]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's auc: 0.72655\tvalid_1's auc: 0.700091\n",
      "[0.77712844 0.5565972  0.72139197 ... 0.77842663 0.75138089 0.78562023]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's auc: 0.720042\tvalid_1's auc: 0.697007\n",
      "[0.79460717 0.58056199 0.75230807 ... 0.7960045  0.75191174 0.79460717]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's auc: 0.7297\tvalid_1's auc: 0.698798\n",
      "[0.75921942 0.57411867 0.70659891 ... 0.75944804 0.7082379  0.76203808]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,263]\u001b[0m Trial 16 finished with value: 0.6973913520080545 and parameters: {'max_depth': 6, 'reg_alpha': 8.521920920262655, 'reg_lambda': 1.0634148600637514e-05, 'num_leaves': 11, 'colsample_bytree': 0.6010747059502135, 'subsample': 0.9223535803832842, 'subsample_freq': 7, 'min_child_samples': 59}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,299]\u001b[0m Trial 17 finished with value: 0.6992872749039303 and parameters: {'max_depth': 10, 'reg_alpha': 3.6303501906201174e-07, 'reg_lambda': 1.4668829637030169e-08, 'num_leaves': 16, 'colsample_bytree': 0.7121877031563392, 'subsample': 0.9939095128598178, 'subsample_freq': 1, 'min_child_samples': 32}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,331]\u001b[0m Trial 18 finished with value: 0.6995090136220349 and parameters: {'max_depth': 15, 'reg_alpha': 0.001552887960640061, 'reg_lambda': 0.0009137626586468019, 'num_leaves': 13, 'colsample_bytree': 0.9268642442869465, 'subsample': 0.8824635558710053, 'subsample_freq': 5, 'min_child_samples': 41}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,360]\u001b[0m Trial 19 finished with value: 0.6985044803729396 and parameters: {'max_depth': 8, 'reg_alpha': 1.311267252520798e-05, 'reg_lambda': 0.011308305775012151, 'num_leaves': 23, 'colsample_bytree': 0.6458910085851192, 'subsample': 0.8327826481280727, 'subsample_freq': 8, 'min_child_samples': 22}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,401]\u001b[0m Trial 20 finished with value: 0.6987014298394815 and parameters: {'max_depth': 5, 'reg_alpha': 7.043853051128721e-05, 'reg_lambda': 1.7417007991992182, 'num_leaves': 18, 'colsample_bytree': 0.7138587292986689, 'subsample': 0.80368290766671, 'subsample_freq': 6, 'min_child_samples': 54}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,440]\u001b[0m Trial 21 finished with value: 0.7001234004394293 and parameters: {'max_depth': 7, 'reg_alpha': 0.1019832708171359, 'reg_lambda': 0.03892184194289435, 'num_leaves': 22, 'colsample_bytree': 0.8874048309151084, 'subsample': 0.942212321338048, 'subsample_freq': 5, 'min_child_samples': 49}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's auc: 0.727035\tvalid_1's auc: 0.697391\n",
      "[0.82504605 0.52770929 0.75062998 ... 0.81048484 0.77307788 0.82594037]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's auc: 0.728011\tvalid_1's auc: 0.699287\n",
      "[0.77031576 0.58074221 0.76362009 ... 0.77273374 0.7435398  0.77521234]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's auc: 0.722769\tvalid_1's auc: 0.699509\n",
      "[0.75994792 0.58721489 0.7611799  ... 0.77185435 0.73452446 0.76520372]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.729902\tvalid_1's auc: 0.698504\n",
      "[0.74243533 0.59293899 0.7196108  ... 0.7444619  0.69618819 0.74783171]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's auc: 0.73793\tvalid_1's auc: 0.698701\n",
      "[0.80626487 0.55185627 0.73153275 ... 0.8124431  0.7474096  0.80860749]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's auc: 0.736891\tvalid_1's auc: 0.700123\n",
      "[0.76870002 0.59462765 0.75512149 ... 0.7736531  0.73328838 0.77667126]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,486]\u001b[0m Trial 22 finished with value: 0.7002971526246928 and parameters: {'max_depth': 7, 'reg_alpha': 3.1449246110115894, 'reg_lambda': 0.24862778924313822, 'num_leaves': 21, 'colsample_bytree': 0.8223571921450672, 'subsample': 0.9369911671248458, 'subsample_freq': 4, 'min_child_samples': 49}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,552]\u001b[0m Trial 23 finished with value: 0.7012515388098476 and parameters: {'max_depth': 9, 'reg_alpha': 0.04950551269218643, 'reg_lambda': 1.2355840992452294, 'num_leaves': 25, 'colsample_bytree': 0.8479060911374328, 'subsample': 0.9942498743668563, 'subsample_freq': 3, 'min_child_samples': 45}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,635]\u001b[0m Trial 24 finished with value: 0.7001038419473709 and parameters: {'max_depth': 9, 'reg_alpha': 0.007292687214661594, 'reg_lambda': 1.7771887754064877, 'num_leaves': 16, 'colsample_bytree': 0.7381590028230031, 'subsample': 0.9965282636315745, 'subsample_freq': 3, 'min_child_samples': 43}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,682]\u001b[0m Trial 25 finished with value: 0.6992812481592843 and parameters: {'max_depth': 10, 'reg_alpha': 0.001038221762455028, 'reg_lambda': 3.626733715894785e-05, 'num_leaves': 25, 'colsample_bytree': 0.5974607990391001, 'subsample': 0.9998443300007438, 'subsample_freq': 2, 'min_child_samples': 37}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.736619\tvalid_1's auc: 0.700297\n",
      "[0.79019607 0.55801481 0.7596909  ... 0.79342381 0.74603358 0.79623072]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.76545\tvalid_1's auc: 0.701252\n",
      "[0.8217295  0.54225654 0.75863897 ... 0.82618061 0.77653449 0.83167564]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's auc: 0.740634\tvalid_1's auc: 0.700104\n",
      "[0.80420377 0.55536448 0.77515548 ... 0.8116389  0.77661642 0.81273548]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's auc: 0.747474\tvalid_1's auc: 0.699281\n",
      "[0.79033332 0.58469343 0.77483689 ... 0.79700169 0.74834358 0.79327331]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,732]\u001b[0m Trial 26 finished with value: 0.7010200208457138 and parameters: {'max_depth': 8, 'reg_alpha': 0.02544325541950892, 'reg_lambda': 0.0005707796651135666, 'num_leaves': 14, 'colsample_bytree': 0.9969489118759565, 'subsample': 0.9855159101433133, 'subsample_freq': 2, 'min_child_samples': 59}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,774]\u001b[0m Trial 27 finished with value: 0.6996549063273314 and parameters: {'max_depth': 8, 'reg_alpha': 0.37820277596562096, 'reg_lambda': 2.240253097953224, 'num_leaves': 10, 'colsample_bytree': 0.9771141231337777, 'subsample': 0.8677141412587387, 'subsample_freq': 1, 'min_child_samples': 58}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,818]\u001b[0m Trial 28 finished with value: 0.7000934941405259 and parameters: {'max_depth': 10, 'reg_alpha': 0.0549832044794324, 'reg_lambda': 0.026991658208096195, 'num_leaves': 13, 'colsample_bytree': 0.9399449243780029, 'subsample': 0.9078718274435842, 'subsample_freq': 2, 'min_child_samples': 63}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,861]\u001b[0m Trial 29 finished with value: 0.70048375428439 and parameters: {'max_depth': 11, 'reg_alpha': 0.030612953937672226, 'reg_lambda': 0.436314905792876, 'num_leaves': 18, 'colsample_bytree': 0.8743004379093477, 'subsample': 0.987852501506446, 'subsample_freq': 2, 'min_child_samples': 51}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's auc: 0.734435\tvalid_1's auc: 0.70102\n",
      "[0.80323725 0.56527757 0.7493191  ... 0.80933816 0.74081254 0.80741359]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's auc: 0.72565\tvalid_1's auc: 0.699655\n",
      "[0.79774118 0.541442   0.74847244 ... 0.80023741 0.75751279 0.79774118]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's auc: 0.731326\tvalid_1's auc: 0.700093\n",
      "[0.80098989 0.57186759 0.76124405 ... 0.79741761 0.78275696 0.80398866]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's auc: 0.733758\tvalid_1's auc: 0.700484\n",
      "[0.78109674 0.58465653 0.7728302  ... 0.7819776  0.76038003 0.78381606]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-07 14:02:24,908]\u001b[0m Trial 30 finished with value: 0.7008165897858731 and parameters: {'max_depth': 8, 'reg_alpha': 1.0996063937192218, 'reg_lambda': 9.66507413990953, 'num_leaves': 15, 'colsample_bytree': 0.9007018671343154, 'subsample': 0.8729871264085705, 'subsample_freq': 3, 'min_child_samples': 55}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,945]\u001b[0m Trial 31 finished with value: 0.7001003168703137 and parameters: {'max_depth': 6, 'reg_alpha': 0.014956220724622778, 'reg_lambda': 0.0005096366750252281, 'num_leaves': 15, 'colsample_bytree': 0.8399247146494038, 'subsample': 0.9503907874123639, 'subsample_freq': 1, 'min_child_samples': 45}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:24,989]\u001b[0m Trial 32 finished with value: 0.6990516633019237 and parameters: {'max_depth': 7, 'reg_alpha': 0.00392417822592046, 'reg_lambda': 0.0003143646048499887, 'num_leaves': 13, 'colsample_bytree': 0.7398757191856262, 'subsample': 0.9813354977307913, 'subsample_freq': 4, 'min_child_samples': 52}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,027]\u001b[0m Trial 33 finished with value: 0.7000149190358027 and parameters: {'max_depth': 9, 'reg_alpha': 0.0009082077022422751, 'reg_lambda': 1.5185466278616087e-06, 'num_leaves': 17, 'colsample_bytree': 0.6788677976729275, 'subsample': 0.9661159155846508, 'subsample_freq': 3, 'min_child_samples': 40}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,056]\u001b[0m Trial 34 finished with value: 0.6988414095122952 and parameters: {'max_depth': 5, 'reg_alpha': 0.034221914277928894, 'reg_lambda': 7.056206467079429e-05, 'num_leaves': 14, 'colsample_bytree': 0.5627869022673031, 'subsample': 0.9722882906396164, 'subsample_freq': 2, 'min_child_samples': 34}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,098]\u001b[0m Trial 35 finished with value: 0.7001304505935433 and parameters: {'max_depth': 11, 'reg_alpha': 0.2693957629598815, 'reg_lambda': 0.14204744146918202, 'num_leaves': 16, 'colsample_bytree': 0.6318176422626284, 'subsample': 0.9833547647263067, 'subsample_freq': 7, 'min_child_samples': 48}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's auc: 0.73282\tvalid_1's auc: 0.700817\n",
      "[0.80687852 0.57081201 0.76382478 ... 0.79986026 0.76758714 0.81148914]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's auc: 0.727758\tvalid_1's auc: 0.7001\n",
      "[0.77062797 0.59279674 0.74322367 ... 0.76904336 0.726015   0.77273449]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.732251\tvalid_1's auc: 0.699052\n",
      "[0.80227509 0.55129171 0.74974784 ... 0.80196606 0.75069855 0.7988853 ]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's auc: 0.732087\tvalid_1's auc: 0.700015\n",
      "[0.77755179 0.57706819 0.77536333 ... 0.78139916 0.73975945 0.78444092]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's auc: 0.725696\tvalid_1's auc: 0.698841\n",
      "[0.75706626 0.59848904 0.75034274 ... 0.76358655 0.72248582 0.76056609]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's auc: 0.731857\tvalid_1's auc: 0.70013\n",
      "[0.78823645 0.55177618 0.7655556  ... 0.79024401 0.74564115 0.7919087 ]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,150]\u001b[0m Trial 36 finished with value: 0.699160713266366 and parameters: {'max_depth': 6, 'reg_alpha': 4.0748685381472066e-08, 'reg_lambda': 1.9562057639484016e-05, 'num_leaves': 18, 'colsample_bytree': 0.9968817258747475, 'subsample': 0.9397544300986777, 'subsample_freq': 3, 'min_child_samples': 58}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,191]\u001b[0m Trial 37 finished with value: 0.7006526168466389 and parameters: {'max_depth': 8, 'reg_alpha': 0.0004489162220566236, 'reg_lambda': 2.0749458666768876e-07, 'num_leaves': 12, 'colsample_bytree': 0.7867059379558758, 'subsample': 0.9996468039155204, 'subsample_freq': 5, 'min_child_samples': 61}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,234]\u001b[0m Trial 38 finished with value: 0.7005658544661703 and parameters: {'max_depth': 9, 'reg_alpha': 5.635912068549134e-05, 'reg_lambda': 0.0012100330391158654, 'num_leaves': 15, 'colsample_bytree': 0.756990089154179, 'subsample': 0.955811536359525, 'subsample_freq': 4, 'min_child_samples': 47}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,285]\u001b[0m Trial 39 finished with value: 0.6997111938480811 and parameters: {'max_depth': 13, 'reg_alpha': 0.7939499463466017, 'reg_lambda': 0.00017145991348448123, 'num_leaves': 19, 'colsample_bytree': 0.8484257459400419, 'subsample': 0.9297173921757026, 'subsample_freq': 3, 'min_child_samples': 52}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's auc: 0.743323\tvalid_1's auc: 0.699161\n",
      "[0.80613508 0.59175976 0.76534221 ... 0.8236838  0.76573181 0.81613857]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's auc: 0.727977\tvalid_1's auc: 0.700653\n",
      "[0.79190981 0.55446557 0.75244091 ... 0.79907931 0.7635359  0.79914221]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's auc: 0.732815\tvalid_1's auc: 0.700566\n",
      "[0.79206604 0.54965265 0.75362017 ... 0.79554252 0.74885325 0.79943345]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's auc: 0.738756\tvalid_1's auc: 0.699711\n",
      "[0.79630879 0.58084753 0.78311792 ... 0.80423106 0.75622727 0.80436998]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-07 14:02:25,318]\u001b[0m Trial 40 finished with value: 0.6989717236512429 and parameters: {'max_depth': 7, 'reg_alpha': 0.011970427153180406, 'reg_lambda': 0.014176750117916175, 'num_leaves': 24, 'colsample_bytree': 0.8033445131825239, 'subsample': 0.9002132905519646, 'subsample_freq': 8, 'min_child_samples': 16}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,372]\u001b[0m Trial 41 finished with value: 0.6993102447608827 and parameters: {'max_depth': 8, 'reg_alpha': 1.758875635357384, 'reg_lambda': 9.543446486651321, 'num_leaves': 15, 'colsample_bytree': 0.9052271083590242, 'subsample': 0.8694074497143814, 'subsample_freq': 3, 'min_child_samples': 54}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,421]\u001b[0m Trial 42 finished with value: 0.6979011236353687 and parameters: {'max_depth': 8, 'reg_alpha': 5.774644082522245, 'reg_lambda': 0.6527490435920037, 'num_leaves': 14, 'colsample_bytree': 0.949216037096844, 'subsample': 0.8471914822346579, 'subsample_freq': 2, 'min_child_samples': 55}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,467]\u001b[0m Trial 43 finished with value: 0.7011031444369622 and parameters: {'max_depth': 11, 'reg_alpha': 0.1231284065916547, 'reg_lambda': 4.76557542053591, 'num_leaves': 16, 'colsample_bytree': 0.9013078824022238, 'subsample': 0.8766464434154113, 'subsample_freq': 3, 'min_child_samples': 61}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,502]\u001b[0m Trial 44 finished with value: 0.6967906106502357 and parameters: {'max_depth': 12, 'reg_alpha': 0.12195546447172527, 'reg_lambda': 0.07607777502995837, 'num_leaves': 17, 'colsample_bytree': 0.9936935155278332, 'subsample': 0.8564453537775075, 'subsample_freq': 6, 'min_child_samples': 62}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's auc: 0.735753\tvalid_1's auc: 0.698972\n",
      "[0.7392753  0.57966619 0.7344126  ... 0.74449278 0.71702248 0.74696054]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.733454\tvalid_1's auc: 0.69931\n",
      "[0.80841349 0.57381217 0.77112231 ... 0.80284712 0.76229724 0.81234418]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's auc: 0.729974\tvalid_1's auc: 0.697901\n",
      "[0.81410668 0.57737174 0.7344969  ... 0.80456316 0.76017696 0.81410668]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's auc: 0.733689\tvalid_1's auc: 0.701103\n",
      "[0.7963621  0.60216454 0.76156229 ... 0.80427127 0.73309252 0.79920083]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's auc: 0.728244\tvalid_1's auc: 0.696791\n",
      "[0.76426966 0.58810453 0.75370472 ... 0.76491171 0.74776163 0.76989907]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,543]\u001b[0m Trial 45 finished with value: 0.6983947481355186 and parameters: {'max_depth': 11, 'reg_alpha': 0.0035998660345403174, 'reg_lambda': 2.575523588243942, 'num_leaves': 16, 'colsample_bytree': 0.8572180802727061, 'subsample': 0.8357279424483318, 'subsample_freq': 2, 'min_child_samples': 59}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,593]\u001b[0m Trial 46 finished with value: 0.700171045835781 and parameters: {'max_depth': 13, 'reg_alpha': 0.05191227477859296, 'reg_lambda': 2.9198890349871483e-06, 'num_leaves': 12, 'colsample_bytree': 0.6582223911956302, 'subsample': 0.8747032199894722, 'subsample_freq': 4, 'min_child_samples': 37}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,629]\u001b[0m Trial 47 finished with value: 0.7004042694823618 and parameters: {'max_depth': 9, 'reg_alpha': 0.2735233348407514, 'reg_lambda': 0.7138595167463447, 'num_leaves': 14, 'colsample_bytree': 0.9221008566351486, 'subsample': 0.9015485358768475, 'subsample_freq': 1, 'min_child_samples': 64}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,661]\u001b[0m Trial 48 finished with value: 0.6994256626064602 and parameters: {'max_depth': 5, 'reg_alpha': 1.7814019340369436e-06, 'reg_lambda': 3.144850659069927e-07, 'num_leaves': 20, 'colsample_bytree': 0.6998358778796999, 'subsample': 0.8913823335807024, 'subsample_freq': 7, 'min_child_samples': 57}. Best is trial 1 with value: 0.7016348625117608.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,733]\u001b[0m Trial 49 finished with value: 0.7020565072126488 and parameters: {'max_depth': 10, 'reg_alpha': 0.020588464488800653, 'reg_lambda': 0.0072620231563443795, 'num_leaves': 17, 'colsample_bytree': 0.7760946649634015, 'subsample': 0.9905813193330342, 'subsample_freq': 3, 'min_child_samples': 43}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's auc: 0.731013\tvalid_1's auc: 0.698395\n",
      "[0.78063607 0.5816143  0.7499412  ... 0.7825708  0.72735916 0.78468891]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.729784\tvalid_1's auc: 0.700171\n",
      "[0.80047684 0.53758469 0.78046158 ... 0.79934427 0.76510319 0.8017677 ]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's auc: 0.725897\tvalid_1's auc: 0.700404\n",
      "[0.76725752 0.5929023  0.74850879 ... 0.767422   0.74136956 0.7726236 ]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's auc: 0.73161\tvalid_1's auc: 0.699426\n",
      "[0.76628822 0.58155322 0.71603507 ... 0.77267099 0.72742524 0.77680755]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's auc: 0.757613\tvalid_1's auc: 0.702057\n",
      "[0.83695649 0.52770033 0.75617728 ... 0.85225747 0.77762217 0.85066698]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,772]\u001b[0m Trial 50 finished with value: 0.6984243132979325 and parameters: {'max_depth': 11, 'reg_alpha': 0.021045875603940212, 'reg_lambda': 0.004298564718883305, 'num_leaves': 9, 'colsample_bytree': 0.8229088978967676, 'subsample': 0.9884824570157916, 'subsample_freq': 3, 'min_child_samples': 44}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,815]\u001b[0m Trial 51 finished with value: 0.7002430256350427 and parameters: {'max_depth': 10, 'reg_alpha': 0.07953444731417643, 'reg_lambda': 0.0015406511928013134, 'num_leaves': 17, 'colsample_bytree': 0.7782243648776287, 'subsample': 0.9647401651716891, 'subsample_freq': 2, 'min_child_samples': 42}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,861]\u001b[0m Trial 52 finished with value: 0.6991814088800556 and parameters: {'max_depth': 12, 'reg_alpha': 0.007157189701918453, 'reg_lambda': 0.00017772607868997634, 'num_leaves': 15, 'colsample_bytree': 0.7257418474813039, 'subsample': 0.971723664001809, 'subsample_freq': 3, 'min_child_samples': 39}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,903]\u001b[0m Trial 53 finished with value: 0.7001835541737254 and parameters: {'max_depth': 9, 'reg_alpha': 0.004340200935776343, 'reg_lambda': 0.007998280324891508, 'num_leaves': 13, 'colsample_bytree': 0.691280504240577, 'subsample': 0.9792537758510113, 'subsample_freq': 4, 'min_child_samples': 46}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,936]\u001b[0m Trial 54 finished with value: 0.7001180559677621 and parameters: {'max_depth': 11, 'reg_alpha': 2.9196948877964786e-07, 'reg_lambda': 0.07805981355589295, 'num_leaves': 16, 'colsample_bytree': 0.7989735845990391, 'subsample': 0.9886911456690528, 'subsample_freq': 5, 'min_child_samples': 31}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's auc: 0.721416\tvalid_1's auc: 0.698424\n",
      "[0.78937414 0.57437205 0.74259787 ... 0.79324921 0.76505135 0.79163157]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's auc: 0.733661\tvalid_1's auc: 0.700243\n",
      "[0.77799875 0.5703029  0.76241207 ... 0.7822688  0.74974779 0.78361239]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.736078\tvalid_1's auc: 0.699181\n",
      "[0.7977459  0.55886261 0.78804768 ... 0.80845639 0.74414133 0.80084607]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's auc: 0.729056\tvalid_1's auc: 0.700184\n",
      "[0.79521143 0.54043259 0.73842396 ... 0.79948827 0.75780572 0.79459791]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's auc: 0.726989\tvalid_1's auc: 0.700118\n",
      "[0.75926128 0.59540267 0.75318651 ... 0.76111578 0.73150759 0.76438046]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:25,975]\u001b[0m Trial 55 finished with value: 0.6972279476296359 and parameters: {'max_depth': 10, 'reg_alpha': 0.17257074108946457, 'reg_lambda': 4.7245771549450115, 'num_leaves': 19, 'colsample_bytree': 0.7666802605058899, 'subsample': 0.8466389827886581, 'subsample_freq': 3, 'min_child_samples': 22}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,019]\u001b[0m Trial 56 finished with value: 0.6998350263937302 and parameters: {'max_depth': 12, 'reg_alpha': 0.54443195566624, 'reg_lambda': 8.600099096961433e-05, 'num_leaves': 18, 'colsample_bytree': 0.8644832379962134, 'subsample': 0.9578218154212885, 'subsample_freq': 4, 'min_child_samples': 61}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,082]\u001b[0m Trial 57 finished with value: 0.6997672539445045 and parameters: {'max_depth': 10, 'reg_alpha': 0.0004615032667751427, 'reg_lambda': 0.0006412910496433163, 'num_leaves': 14, 'colsample_bytree': 0.8241621044099356, 'subsample': 0.8218740747348481, 'subsample_freq': 2, 'min_child_samples': 49}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,123]\u001b[0m Trial 58 finished with value: 0.699750310832198 and parameters: {'max_depth': 6, 'reg_alpha': 0.001920786619504501, 'reg_lambda': 0.27109228409797337, 'num_leaves': 11, 'colsample_bytree': 0.7222765433747146, 'subsample': 0.8590640504057212, 'subsample_freq': 6, 'min_child_samples': 51}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's auc: 0.731501\tvalid_1's auc: 0.697228\n",
      "[0.76448614 0.60110563 0.75985294 ... 0.75854177 0.72873756 0.76448614]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.734333\tvalid_1's auc: 0.699835\n",
      "[0.78567786 0.58852712 0.76714136 ... 0.7880307  0.7438906  0.79289875]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's auc: 0.748454\tvalid_1's auc: 0.699767\n",
      "[0.82827199 0.56498564 0.77187562 ... 0.83921305 0.73816804 0.83358872]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's auc: 0.728352\tvalid_1's auc: 0.69975\n",
      "[0.79633432 0.591092   0.74542381 ... 0.80648339 0.77341285 0.80157795]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-07 14:02:26,175]\u001b[0m Trial 59 finished with value: 0.7010182014511037 and parameters: {'max_depth': 9, 'reg_alpha': 0.024100247342515594, 'reg_lambda': 0.9149148156014257, 'num_leaves': 17, 'colsample_bytree': 0.9703474501820223, 'subsample': 0.9955432064098164, 'subsample_freq': 3, 'min_child_samples': 39}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,213]\u001b[0m Trial 60 finished with value: 0.7001869655386193 and parameters: {'max_depth': 9, 'reg_alpha': 1.634889107977277e-05, 'reg_lambda': 1.004521124022375, 'num_leaves': 20, 'colsample_bytree': 0.968791582140066, 'subsample': 0.8862001064713018, 'subsample_freq': 3, 'min_child_samples': 42}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,265]\u001b[0m Trial 61 finished with value: 0.7008927769351707 and parameters: {'max_depth': 9, 'reg_alpha': 0.03003129849371447, 'reg_lambda': 2.870073701821509, 'num_leaves': 17, 'colsample_bytree': 0.950689980630553, 'subsample': 0.9931393792378422, 'subsample_freq': 3, 'min_child_samples': 26}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,309]\u001b[0m Trial 62 finished with value: 0.700420985170342 and parameters: {'max_depth': 8, 'reg_alpha': 0.014232259852200297, 'reg_lambda': 1.3002348110458914, 'num_leaves': 16, 'colsample_bytree': 0.883773513722845, 'subsample': 0.9995475913615605, 'subsample_freq': 4, 'min_child_samples': 60}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,349]\u001b[0m Trial 63 finished with value: 0.7006111119070962 and parameters: {'max_depth': 10, 'reg_alpha': 0.05275059701738899, 'reg_lambda': 4.620516031817549, 'num_leaves': 15, 'colsample_bytree': 0.9812065993676524, 'subsample': 0.9759364436202591, 'subsample_freq': 2, 'min_child_samples': 40}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's auc: 0.738174\tvalid_1's auc: 0.701018\n",
      "[0.79779977 0.56525703 0.74151774 ... 0.79909555 0.75106351 0.80447254]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's auc: 0.732982\tvalid_1's auc: 0.700187\n",
      "[0.76628938 0.59784711 0.76090935 ... 0.76366781 0.74238163 0.77173247]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.739303\tvalid_1's auc: 0.700893\n",
      "[0.79800266 0.54532605 0.75002804 ... 0.80279193 0.76275952 0.80445462]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's auc: 0.732114\tvalid_1's auc: 0.700421\n",
      "[0.78748221 0.55827372 0.76492781 ... 0.79136337 0.7590914  0.79414793]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's auc: 0.728499\tvalid_1's auc: 0.700611\n",
      "[0.7743438  0.5834105  0.77044041 ... 0.77880735 0.75708413 0.77696693]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,401]\u001b[0m Trial 64 finished with value: 0.7006272590342608 and parameters: {'max_depth': 8, 'reg_alpha': 0.02385559899605447, 'reg_lambda': 0.39455533582442753, 'num_leaves': 18, 'colsample_bytree': 0.9243199873304138, 'subsample': 0.9924463247004444, 'subsample_freq': 1, 'min_child_samples': 38}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,441]\u001b[0m Trial 65 finished with value: 0.69834903584594 and parameters: {'max_depth': 7, 'reg_alpha': 0.00015942364573796972, 'reg_lambda': 0.11499313427886612, 'num_leaves': 13, 'colsample_bytree': 0.6148267954656711, 'subsample': 0.9823458693009176, 'subsample_freq': 3, 'min_child_samples': 35}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,476]\u001b[0m Trial 66 finished with value: 0.6969372993406742 and parameters: {'max_depth': 9, 'reg_alpha': 0.007548080487978901, 'reg_lambda': 0.0019051504947421862, 'num_leaves': 17, 'colsample_bytree': 0.7449662948185718, 'subsample': 0.8796344972610523, 'subsample_freq': 2, 'min_child_samples': 56}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,530]\u001b[0m Trial 67 finished with value: 0.7001075944487541 and parameters: {'max_depth': 10, 'reg_alpha': 0.11457936829320856, 'reg_lambda': 0.0003548047282125977, 'num_leaves': 22, 'colsample_bytree': 0.6598897987584741, 'subsample': 0.861485776367986, 'subsample_freq': 5, 'min_child_samples': 32}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,573]\u001b[0m Trial 68 finished with value: 0.7003679953023232 and parameters: {'max_depth': 11, 'reg_alpha': 1.1201823056367394e-08, 'reg_lambda': 0.022331381221727505, 'num_leaves': 16, 'colsample_bytree': 0.6795931785441001, 'subsample': 0.9754013972445514, 'subsample_freq': 4, 'min_child_samples': 44}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's auc: 0.73495\tvalid_1's auc: 0.700627\n",
      "[0.78131111 0.55439869 0.77503463 ... 0.7834646  0.75943009 0.78550279]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's auc: 0.728143\tvalid_1's auc: 0.698349\n",
      "[0.78616154 0.59284237 0.76851989 ... 0.78990902 0.74630978 0.78878484]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's auc: 0.728501\tvalid_1's auc: 0.696937\n",
      "[0.7663421  0.57699697 0.75736033 ... 0.76330772 0.73772887 0.76893328]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.750175\tvalid_1's auc: 0.700108\n",
      "[0.80440107 0.58132854 0.77148248 ... 0.8137406  0.75710412 0.81052196]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's auc: 0.73287\tvalid_1's auc: 0.700368\n",
      "[0.78901127 0.54762166 0.75997635 ... 0.79281781 0.75253884 0.79261265]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,607]\u001b[0m Trial 69 finished with value: 0.6977795653329821 and parameters: {'max_depth': 7, 'reg_alpha': 0.19066238263098054, 'reg_lambda': 6.425906497775665e-05, 'num_leaves': 14, 'colsample_bytree': 0.9615959197780118, 'subsample': 0.8513539590349437, 'subsample_freq': 8, 'min_child_samples': 21}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,653]\u001b[0m Trial 70 finished with value: 0.701472254118484 and parameters: {'max_depth': 9, 'reg_alpha': 0.0703792828734252, 'reg_lambda': 0.006245744057867143, 'num_leaves': 15, 'colsample_bytree': 0.9030499499147644, 'subsample': 0.8342880195800079, 'subsample_freq': 3, 'min_child_samples': 50}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,701]\u001b[0m Trial 71 finished with value: 0.7013148764847112 and parameters: {'max_depth': 9, 'reg_alpha': 0.056726774643520265, 'reg_lambda': 0.005107776478304498, 'num_leaves': 15, 'colsample_bytree': 0.9104514256333138, 'subsample': 0.8251064606826654, 'subsample_freq': 3, 'min_child_samples': 50}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,738]\u001b[0m Trial 72 finished with value: 0.6965526110928035 and parameters: {'max_depth': 9, 'reg_alpha': 0.0715777162168991, 'reg_lambda': 0.006963870246155901, 'num_leaves': 15, 'colsample_bytree': 0.9117627013901002, 'subsample': 0.8068155188296781, 'subsample_freq': 3, 'min_child_samples': 47}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,789]\u001b[0m Trial 73 finished with value: 0.6982640928600816 and parameters: {'max_depth': 9, 'reg_alpha': 0.5888949037045492, 'reg_lambda': 0.0028333562278858564, 'num_leaves': 16, 'colsample_bytree': 0.9417643372316048, 'subsample': 0.820725135939352, 'subsample_freq': 3, 'min_child_samples': 53}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's auc: 0.723876\tvalid_1's auc: 0.69778\n",
      "[0.75900876 0.60251018 0.68791835 ... 0.76244885 0.74212378 0.76480904]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's auc: 0.733618\tvalid_1's auc: 0.701472\n",
      "[0.79627783 0.57124927 0.73558244 ... 0.79671522 0.75253055 0.79627783]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's auc: 0.733426\tvalid_1's auc: 0.701315\n",
      "[0.7931447  0.56860332 0.73615555 ... 0.79582581 0.73974983 0.79600002]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's auc: 0.72844\tvalid_1's auc: 0.696553\n",
      "[0.77063707 0.56937023 0.74402055 ... 0.7681544  0.75247353 0.77063707]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.737218\tvalid_1's auc: 0.698264\n",
      "[0.80696695 0.5456674  0.7589022  ... 0.81034405 0.74859219 0.80925823]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,839]\u001b[0m Trial 74 finished with value: 0.7009587299897864 and parameters: {'max_depth': 8, 'reg_alpha': 0.03472940928719846, 'reg_lambda': 0.04980881295620562, 'num_leaves': 17, 'colsample_bytree': 0.8960108822288353, 'subsample': 0.8310795710866294, 'subsample_freq': 3, 'min_child_samples': 50}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,886]\u001b[0m Trial 75 finished with value: 0.6986850552879909 and parameters: {'max_depth': 10, 'reg_alpha': 0.3529463980780338, 'reg_lambda': 0.00417702137516906, 'num_leaves': 13, 'colsample_bytree': 0.8787987264514707, 'subsample': 0.8366337678082074, 'subsample_freq': 2, 'min_child_samples': 48}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,937]\u001b[0m Trial 76 finished with value: 0.6995895218335313 and parameters: {'max_depth': 9, 'reg_alpha': 1.933481527187307, 'reg_lambda': 0.01792918305878899, 'num_leaves': 16, 'colsample_bytree': 0.836134583338472, 'subsample': 0.8145161198587012, 'subsample_freq': 4, 'min_child_samples': 50}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:26,981]\u001b[0m Trial 77 finished with value: 0.6991907332774324 and parameters: {'max_depth': 8, 'reg_alpha': 0.019303625370948263, 'reg_lambda': 0.0008807510664209842, 'num_leaves': 15, 'colsample_bytree': 0.9326725971145542, 'subsample': 0.8403787267537361, 'subsample_freq': 3, 'min_child_samples': 46}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,030]\u001b[0m Trial 78 finished with value: 0.6971146903151577 and parameters: {'max_depth': 10, 'reg_alpha': 0.1839082502701324, 'reg_lambda': 0.18742465287312676, 'num_leaves': 12, 'colsample_bytree': 0.9883167705963172, 'subsample': 0.8263791461620998, 'subsample_freq': 2, 'min_child_samples': 53}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's auc: 0.736009\tvalid_1's auc: 0.700959\n",
      "[0.79683129 0.56896064 0.74975407 ... 0.79542732 0.73644846 0.79683129]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.732166\tvalid_1's auc: 0.698685\n",
      "[0.80234293 0.54978759 0.75016133 ... 0.80302752 0.76726632 0.80234293]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's auc: 0.737273\tvalid_1's auc: 0.69959\n",
      "[0.81872234 0.5467777  0.75253545 ... 0.81517625 0.75133547 0.81645492]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's auc: 0.733779\tvalid_1's auc: 0.699191\n",
      "[0.79284844 0.57504498 0.74591756 ... 0.79535852 0.72375528 0.7941709 ]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's auc: 0.731943\tvalid_1's auc: 0.697115\n",
      "[0.80599566 0.5301304  0.72676415 ... 0.81431133 0.74068624 0.81354379]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,075]\u001b[0m Trial 79 finished with value: 0.6985977243467065 and parameters: {'max_depth': 8, 'reg_alpha': 0.05031620382117965, 'reg_lambda': 0.007609419925276338, 'num_leaves': 14, 'colsample_bytree': 0.911798087736517, 'subsample': 0.8416281278280675, 'subsample_freq': 3, 'min_child_samples': 43}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,115]\u001b[0m Trial 80 finished with value: 0.6996881102789655 and parameters: {'max_depth': 9, 'reg_alpha': 0.011956705617418982, 'reg_lambda': 0.032806864658141414, 'num_leaves': 19, 'colsample_bytree': 0.8923213544321804, 'subsample': 0.8657190196419389, 'subsample_freq': 4, 'min_child_samples': 41}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,164]\u001b[0m Trial 81 finished with value: 0.699839233743766 and parameters: {'max_depth': 8, 'reg_alpha': 0.04363531086234127, 'reg_lambda': 0.07371946235893055, 'num_leaves': 18, 'colsample_bytree': 0.8979729498800608, 'subsample': 0.8293984631243416, 'subsample_freq': 3, 'min_child_samples': 50}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,213]\u001b[0m Trial 82 finished with value: 0.6987196237855826 and parameters: {'max_depth': 7, 'reg_alpha': 0.11466349193152425, 'reg_lambda': 0.05215352463786234, 'num_leaves': 17, 'colsample_bytree': 0.8649732996233895, 'subsample': 0.8126680916324577, 'subsample_freq': 3, 'min_child_samples': 51}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's auc: 0.731828\tvalid_1's auc: 0.698598\n",
      "[0.79397848 0.59073094 0.75154218 ... 0.79174813 0.7306699  0.79397848]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's auc: 0.73382\tvalid_1's auc: 0.699688\n",
      "[0.77450464 0.57462364 0.7560429  ... 0.77581863 0.74567071 0.78111882]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's auc: 0.740475\tvalid_1's auc: 0.699839\n",
      "[0.80916794 0.58612645 0.73054379 ... 0.80922787 0.74660043 0.80916794]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's auc: 0.737732\tvalid_1's auc: 0.69872\n",
      "[0.80693399 0.54172516 0.73224709 ... 0.80163067 0.73447652 0.80919814]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-07 14:02:27,265]\u001b[0m Trial 83 finished with value: 0.6995392610574276 and parameters: {'max_depth': 9, 'reg_alpha': 0.0045553207359498825, 'reg_lambda': 0.013280979057981934, 'num_leaves': 17, 'colsample_bytree': 0.9132506532436737, 'subsample': 0.8520984029429776, 'subsample_freq': 3, 'min_child_samples': 46}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,306]\u001b[0m Trial 84 finished with value: 0.6998458290492277 and parameters: {'max_depth': 8, 'reg_alpha': 0.02900374802849917, 'reg_lambda': 0.620900361744824, 'num_leaves': 15, 'colsample_bytree': 0.8504323428035953, 'subsample': 0.8336060877863719, 'subsample_freq': 2, 'min_child_samples': 54}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,340]\u001b[0m Trial 85 finished with value: 0.697093085004163 and parameters: {'max_depth': 8, 'reg_alpha': 0.08927795281174675, 'reg_lambda': 0.37707958529634306, 'num_leaves': 18, 'colsample_bytree': 0.9568333766884805, 'subsample': 0.8005891547941526, 'subsample_freq': 3, 'min_child_samples': 44}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,386]\u001b[0m Trial 86 finished with value: 0.6993221845380113 and parameters: {'max_depth': 11, 'reg_alpha': 0.002990791031468213, 'reg_lambda': 0.12755951562340737, 'num_leaves': 23, 'colsample_bytree': 0.9326524432406649, 'subsample': 0.818994473433606, 'subsample_freq': 2, 'min_child_samples': 57}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,435]\u001b[0m Trial 87 finished with value: 0.6999847853125731 and parameters: {'max_depth': 10, 'reg_alpha': 0.008093664997423913, 'reg_lambda': 1.0948990640677483, 'num_leaves': 16, 'colsample_bytree': 0.8726906095578001, 'subsample': 0.8282034168425798, 'subsample_freq': 4, 'min_child_samples': 64}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.740559\tvalid_1's auc: 0.699539\n",
      "[0.8055678  0.5900861  0.76335175 ... 0.80405802 0.75242323 0.81137569]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's auc: 0.731162\tvalid_1's auc: 0.699846\n",
      "[0.78423846 0.56667477 0.745306   ... 0.78500119 0.73347043 0.78920004]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.72894\tvalid_1's auc: 0.697093\n",
      "[0.7570283  0.60331575 0.74846176 ... 0.75741784 0.73647967 0.76006436]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's auc: 0.740888\tvalid_1's auc: 0.699322\n",
      "[0.78583085 0.58664598 0.7468063  ... 0.78162192 0.74716082 0.79008934]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.737803\tvalid_1's auc: 0.699985\n",
      "[0.80820902 0.53471697 0.78301283 ... 0.80977207 0.74166538 0.80915617]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.722932\tvalid_1's auc: 0.695722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,465]\u001b[0m Trial 88 finished with value: 0.6957223985897872 and parameters: {'max_depth': 9, 'reg_alpha': 0.20580886468694454, 'reg_lambda': 0.034256228696322034, 'num_leaves': 14, 'colsample_bytree': 0.8946081440939163, 'subsample': 0.807890141743692, 'subsample_freq': 3, 'min_child_samples': 49}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,515]\u001b[0m Trial 89 finished with value: 0.7002844168624222 and parameters: {'max_depth': 8, 'reg_alpha': 0.01603341359511025, 'reg_lambda': 3.503456995924034, 'num_leaves': 15, 'colsample_bytree': 0.8853511793782819, 'subsample': 0.8390413297248407, 'subsample_freq': 3, 'min_child_samples': 53}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,554]\u001b[0m Trial 90 finished with value: 0.7008521816929331 and parameters: {'max_depth': 7, 'reg_alpha': 0.03437955615035716, 'reg_lambda': 0.005353350758240187, 'num_leaves': 16, 'colsample_bytree': 0.9396433259583009, 'subsample': 0.9112617756611918, 'subsample_freq': 2, 'min_child_samples': 59}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,598]\u001b[0m Trial 91 finished with value: 0.6994974149813955 and parameters: {'max_depth': 6, 'reg_alpha': 0.0008552181254726732, 'reg_lambda': 0.000284235697011758, 'num_leaves': 17, 'colsample_bytree': 0.9712178057297334, 'subsample': 0.985962315200477, 'subsample_freq': 4, 'min_child_samples': 56}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,637]\u001b[0m Trial 92 finished with value: 0.6985314301556014 and parameters: {'max_depth': 4, 'reg_alpha': 0.06444564665403481, 'reg_lambda': 0.0024800973132521127, 'num_leaves': 15, 'colsample_bytree': 0.8121604413253842, 'subsample': 0.9902179162444507, 'subsample_freq': 3, 'min_child_samples': 47}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73728518 0.60582024 0.73726385 ... 0.73528621 0.71575769 0.73728518]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's auc: 0.732822\tvalid_1's auc: 0.700284\n",
      "[0.79543013 0.59894234 0.73022464 ... 0.79664119 0.74149898 0.79543013]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's auc: 0.72878\tvalid_1's auc: 0.700852\n",
      "[0.76915787 0.59378231 0.75627839 ... 0.77158459 0.75826642 0.77523759]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's auc: 0.734898\tvalid_1's auc: 0.699497\n",
      "[0.79163338 0.56765654 0.75505819 ... 0.79209351 0.76170079 0.7984424 ]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's auc: 0.730013\tvalid_1's auc: 0.698531\n",
      "[0.78588381 0.55280254 0.76988248 ... 0.79720497 0.74054611 0.7951203 ]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,678]\u001b[0m Trial 93 finished with value: 0.7006100884976281 and parameters: {'max_depth': 9, 'reg_alpha': 0.005603124986586876, 'reg_lambda': 0.0012135598046239687, 'num_leaves': 16, 'colsample_bytree': 0.7549010708685544, 'subsample': 0.9975755143697583, 'subsample_freq': 7, 'min_child_samples': 50}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,729]\u001b[0m Trial 94 finished with value: 0.6992357632940321 and parameters: {'max_depth': 10, 'reg_alpha': 4.014550218520718e-06, 'reg_lambda': 1.6876534458978052, 'num_leaves': 14, 'colsample_bytree': 0.6415634097238352, 'subsample': 0.8454021418345036, 'subsample_freq': 3, 'min_child_samples': 62}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,775]\u001b[0m Trial 95 finished with value: 0.6992955758918389 and parameters: {'max_depth': 11, 'reg_alpha': 0.0014624637195173856, 'reg_lambda': 3.576608636817923e-05, 'num_leaves': 13, 'colsample_bytree': 0.69658128338143, 'subsample': 0.9960192255251661, 'subsample_freq': 4, 'min_child_samples': 52}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,823]\u001b[0m Trial 96 finished with value: 0.6996628661787505 and parameters: {'max_depth': 7, 'reg_alpha': 0.020813902964383773, 'reg_lambda': 6.361079859273232, 'num_leaves': 15, 'colsample_bytree': 0.8367286464064819, 'subsample': 0.9693029654502142, 'subsample_freq': 6, 'min_child_samples': 45}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's auc: 0.730126\tvalid_1's auc: 0.70061\n",
      "[0.77689742 0.56913023 0.77125665 ... 0.78072841 0.74123761 0.78390324]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's auc: 0.735704\tvalid_1's auc: 0.699236\n",
      "[0.81921195 0.59883053 0.77044574 ... 0.81742558 0.74301179 0.81820367]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's auc: 0.732368\tvalid_1's auc: 0.699296\n",
      "[0.80131181 0.52764467 0.76159846 ... 0.8075844  0.75869998 0.8051108 ]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.736087\tvalid_1's auc: 0.699663\n",
      "[0.8001429  0.56249204 0.75458419 ... 0.80386491 0.7408439  0.8025632 ]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-07 14:02:27,880]\u001b[0m Trial 97 finished with value: 0.6990567803492647 and parameters: {'max_depth': 10, 'reg_alpha': 0.011268993521266278, 'reg_lambda': 0.010918542455586313, 'num_leaves': 21, 'colsample_bytree': 0.7082229842194017, 'subsample': 0.832033907517717, 'subsample_freq': 2, 'min_child_samples': 48}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,932]\u001b[0m Trial 98 finished with value: 0.6990915762711826 and parameters: {'max_depth': 8, 'reg_alpha': 0.14576959752286883, 'reg_lambda': 0.24410014025024948, 'num_leaves': 25, 'colsample_bytree': 0.7341562469547347, 'subsample': 0.9796501900739665, 'subsample_freq': 3, 'min_child_samples': 55}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 14:02:27,987]\u001b[0m Trial 99 finished with value: 0.7007874794721117 and parameters: {'max_depth': 9, 'reg_alpha': 0.08591505522365636, 'reg_lambda': 0.0004290086642958847, 'num_leaves': 17, 'colsample_bytree': 0.7797285257947614, 'subsample': 0.9850751054994973, 'subsample_freq': 3, 'min_child_samples': 42}. Best is trial 49 with value: 0.7020565072126488.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's auc: 0.749303\tvalid_1's auc: 0.699057\n",
      "[0.81268351 0.5836007  0.77168601 ... 0.81009384 0.74522255 0.81523476]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.744679\tvalid_1's auc: 0.699092\n",
      "[0.79022886 0.59090326 0.77386765 ... 0.7881428  0.7222964  0.79605525]\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.667726\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's auc: 0.741859\tvalid_1's auc: 0.700787\n",
      "[0.80757523 0.55613591 0.7679916  ... 0.80946634 0.7304683  0.81401175]\n",
      "trial 100\n",
      "best_trail {'max_depth': 10, 'reg_alpha': 0.020588464488800653, 'reg_lambda': 0.0072620231563443795, 'num_leaves': 17, 'colsample_bytree': 0.7760946649634015, 'subsample': 0.9905813193330342, 'subsample_freq': 3, 'min_child_samples': 43}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "print(\"trial\",len(study.trials))\n",
    "print('best_trail', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터\n",
    "# param1={\"num_leaves\":150,\n",
    "#         \"max_bin\":200,\n",
    "#        \"feature_fraction\":0.52,\n",
    "#        \"bagging_fraction\":0.52,\n",
    "#        \"objective\":\"binary\",\n",
    "#        \"learning_rate\":0.05,\n",
    "#        \"boosting_type\":\"gbdt\",\n",
    "#        \"metric\":\"auc\"\n",
    "#        }\n",
    "# param2={\"num_leaves\":100,\n",
    "#        \"max_bin\":200,\n",
    "#        \"feature_fraction\":0.52,\n",
    "#        \"bagging_fraction\":0.52,\n",
    "#        \"objective\":\"binary\",\n",
    "#        \"learning_rate\":0.05,\n",
    "       \n",
    "#        \"metric\":\"auc\"\n",
    "#        }\n",
    "\n",
    "param1 = {'max_depth': 4,\n",
    "          'reg_alpha': 1.1368236970200307e-05, \n",
    "          'reg_lambda': 4.6208018285505224e-06, \n",
    "          'num_leaves': 8,\n",
    "          'colsample_bytree': 0.9476860631912927, \n",
    "          'subsample': 0.8466146128214767,\n",
    "          'subsample_freq': 2,\n",
    "          'min_child_samples': 48,\n",
    "          \"metric\":\"auc\",\n",
    "          \"boosting_type\":\"gbdt\",\n",
    "          \"objective\":\"binary\",\n",
    "          }\n",
    "param2 = {'max_depth': 6, \n",
    "          'reg_alpha': 1.6114208357018784e-08,\n",
    "          'reg_lambda': 0.00013461567148605243,\n",
    "          'num_leaves': 32,\n",
    "          'colsample_bytree': 0.7544537836898809,\n",
    "          'subsample': 0.8536948315468904,\n",
    "          'subsample_freq': 6,\n",
    "          'min_child_samples': 49,\n",
    "          \"metric\":\"auc\",\n",
    "          \"boosting_type\":\"gbdt\",\n",
    "          }\n",
    "param3 = {'max_depth': 15,\n",
    "          'reg_alpha': 9.782691045632198e-05, \n",
    "          'reg_lambda': 0.361168894005083,\n",
    "          'num_leaves': 15,\n",
    "          'colsample_bytree': 0.8067711071360085,\n",
    "          'subsample': 0.9660844252408497,\n",
    "          'subsample_freq': 4,\n",
    "          'min_child_samples': 36,\n",
    "          \"metric\":\"auc\",\n",
    "          \"boosting_type\":\"gbdt\",\n",
    "          \"objective\":\"binary\",\n",
    "          }\n",
    "param4 = {'max_depth': 10,\n",
    "          'reg_alpha': 0.020588464488800653,\n",
    "          'reg_lambda': 0.0072620231563443795,\n",
    "          'num_leaves': 17, \n",
    "          'colsample_bytree': 0.7760946649634015,\n",
    "          'subsample': 0.9905813193330342,\n",
    "          'subsample_freq': 3,\n",
    "          'min_child_samples': 43,\n",
    "          \"metric\":\"auc\",\n",
    "          \"boosting_type\":\"gbdt\",}\n",
    "\n",
    "\n",
    "params = [param3, param2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[LightGBM] [Info] Number of positive: 6935, number of negative: 3451\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.667726 -> initscore=0.697917\n",
      "[LightGBM] [Info] Start training from score 0.697917\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's auc: 0.748048\tvalid_1's auc: 0.702662\n",
      "1\n",
      "[LightGBM] [Info] Total Bins 5552\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 0.797516\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's auc: 0.726707\tvalid_1's auc: 0.567836\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "\n",
    "models = []\n",
    "for  i in range(2):\n",
    "    print(i)\n",
    "    train = lgbm.Dataset(x_train, y_train.iloc[:,i])\n",
    "    test = lgbm.Dataset(x_test, y_test.iloc[:,i])\n",
    "    model = lgbm.train(params=params[i], train_set=train, valid_sets=[train, test], num_boost_round=500, early_stopping_rounds=10, verbose_eval=100)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission[['id']]\n",
    "\n",
    "ec1 = pd.DataFrame(models[0].predict(test_df), columns=['EC1'])\n",
    "ec2 = pd.DataFrame(models[1].predict(test_df), columns=['EC2'])\n",
    "submission = pd.concat([submission, ec1, ec2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission.to_csv('submit_04_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
