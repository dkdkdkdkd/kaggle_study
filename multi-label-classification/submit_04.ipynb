{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optuna 튜닝\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc\n",
    "plt.style.use(\"ggplot\")\n",
    "import lightgbm as lgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../Data/multi-label-classification-data/train_process.csv')\n",
    "test_df = pd.read_csv('../Data/multi-label-classification-data/test.csv')\n",
    "label_df = pd.read_csv('../Data/multi-label-classification-data/label.csv')\n",
    "submission = pd.read_csv('../Data/multi-label-classification-data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['id','FpDensityMorgan1', 'FpDensityMorgan2','FpDensityMorgan3'], axis=1)\n",
    "test_df = test_df.drop(['id','FpDensityMorgan1', 'FpDensityMorgan2','FpDensityMorgan3'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skew_feature = ['BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3v', 'Chi4n',\n",
    "#        'EState_VSA1', 'EState_VSA2', 'ExactMolWt', 'FpDensityMorgan1',\n",
    "#        'FpDensityMorgan2', 'FpDensityMorgan3',\n",
    "#        'HeavyAtomMolWt', 'Kappa3', \n",
    "#        'NumHeteroatoms', 'PEOE_VSA10', 'PEOE_VSA14', 'PEOE_VSA6', 'PEOE_VSA7',\n",
    "#        'PEOE_VSA8', 'SMR_VSA10', 'SMR_VSA5', 'SlogP_VSA3', 'VSA_EState9',\n",
    "#        ]\n",
    "skew_feature = [ 'Kappa3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "for col in skew_feature:\n",
    "    train_df[col] = np.log1p(train_df[col])\n",
    "    test_df[col] = np.log1p(test_df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 검증 데이터 분할\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_df, label_df,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = label_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna 사용\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "train = lgbm.Dataset(x_train, y_train.iloc[:,0])\n",
    "test = lgbm.Dataset(x_test, y_test.iloc[:,0])\n",
    "def objective(trial : Trial):\n",
    "    params = {\n",
    "        'boosting_type' : 'gbdt',\n",
    "        \"n_estimators\" : 10000,\n",
    "#         'fold_size':trial.suggest_int('fold_size', 4, 16),\n",
    "        'max_depth':trial.suggest_int('max_depth', 4, 16),\n",
    "        'random_state': 722,\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 10.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 8, 25),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.8, 1.0),\n",
    "        'subsample_freq': trial.suggest_int('subsample_freq', 1, 8),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 16, 64),\n",
    "        'learning_rate': 0.05,\n",
    "        \"metric\":\"auc\"\n",
    "    }\n",
    "    \n",
    "    model = lgbm.train(params=params, train_set=train, valid_sets=[train, test], num_boost_round=500, early_stopping_rounds=10, verbose_eval=100)\n",
    "    preds = model.predict(x_test)\n",
    "    print(preds)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test['EC1'], preds, pos_label=1)\n",
    "    \n",
    "    score = auc(fpr, tpr)\n",
    "    \n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:01,730]\u001b[0m Trial 0 finished with value: 0.7151372239577389 and parameters: {'max_depth': 12, 'reg_alpha': 0.00420419296206051, 'reg_lambda': 0.15614653920958144, 'num_leaves': 15, 'colsample_bytree': 0.857093654788634, 'subsample': 0.8774383496487371, 'subsample_freq': 3, 'min_child_samples': 30}. Best is trial 0 with value: 0.7151372239577389.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:01,770]\u001b[0m Trial 1 finished with value: 0.7163176253447335 and parameters: {'max_depth': 11, 'reg_alpha': 3.724541302975877e-05, 'reg_lambda': 5.239813168008782e-06, 'num_leaves': 10, 'colsample_bytree': 0.6070736338103251, 'subsample': 0.876305030303014, 'subsample_freq': 3, 'min_child_samples': 60}. Best is trial 1 with value: 0.7163176253447335.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:01,809]\u001b[0m Trial 2 finished with value: 0.7145969721556173 and parameters: {'max_depth': 15, 'reg_alpha': 9.331573984936053, 'reg_lambda': 2.1880167957204108e-07, 'num_leaves': 23, 'colsample_bytree': 0.6323075437132448, 'subsample': 0.882956930116253, 'subsample_freq': 5, 'min_child_samples': 16}. Best is trial 1 with value: 0.7163176253447335.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's auc: 0.740454\tvalid_1's auc: 0.715137\n",
      "[0.8137905  0.50669855 0.74420077 ... 0.50953958 0.77892863 0.46777087]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's auc: 0.723977\tvalid_1's auc: 0.716318\n",
      "[0.80150425 0.48100845 0.75906508 ... 0.52729596 0.76238018 0.47676246]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's auc: 0.727549\tvalid_1's auc: 0.714597\n",
      "[0.79111896 0.49490575 0.73360722 ... 0.52077357 0.72728013 0.48739097]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-07 13:26:01,895]\u001b[0m Trial 3 finished with value: 0.7155674733737962 and parameters: {'max_depth': 4, 'reg_alpha': 0.07847714011798672, 'reg_lambda': 8.978909363827826, 'num_leaves': 15, 'colsample_bytree': 0.8503227686267543, 'subsample': 0.8630060761080658, 'subsample_freq': 2, 'min_child_samples': 39}. Best is trial 1 with value: 0.7163176253447335.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:01,925]\u001b[0m Trial 4 finished with value: 0.7129340759604368 and parameters: {'max_depth': 16, 'reg_alpha': 0.19568039103955048, 'reg_lambda': 0.008825125973778868, 'num_leaves': 19, 'colsample_bytree': 0.8082103101213838, 'subsample': 0.9898617698557086, 'subsample_freq': 6, 'min_child_samples': 27}. Best is trial 1 with value: 0.7163176253447335.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:01,949]\u001b[0m Trial 5 finished with value: 0.7091288890379063 and parameters: {'max_depth': 9, 'reg_alpha': 3.609394131641888, 'reg_lambda': 0.0008148000401510404, 'num_leaves': 24, 'colsample_bytree': 0.8613808952040467, 'subsample': 0.8273846931824972, 'subsample_freq': 2, 'min_child_samples': 41}. Best is trial 1 with value: 0.7163176253447335.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:01,996]\u001b[0m Trial 6 finished with value: 0.7148947134782317 and parameters: {'max_depth': 16, 'reg_alpha': 9.78821820878918, 'reg_lambda': 0.4061669556246941, 'num_leaves': 17, 'colsample_bytree': 0.6018388241532291, 'subsample': 0.9027005015323336, 'subsample_freq': 5, 'min_child_samples': 35}. Best is trial 1 with value: 0.7163176253447335.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,020]\u001b[0m Trial 7 finished with value: 0.7147058262913051 and parameters: {'max_depth': 16, 'reg_alpha': 4.5016987355922715e-06, 'reg_lambda': 2.0856633447555614e-05, 'num_leaves': 16, 'colsample_bytree': 0.5069293499130862, 'subsample': 0.9672437977538507, 'subsample_freq': 4, 'min_child_samples': 38}. Best is trial 1 with value: 0.7163176253447335.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,055]\u001b[0m Trial 8 finished with value: 0.7143459646233246 and parameters: {'max_depth': 15, 'reg_alpha': 2.0484076852224913e-07, 'reg_lambda': 3.515006348048506e-08, 'num_leaves': 21, 'colsample_bytree': 0.6994826372704519, 'subsample': 0.8779116152462019, 'subsample_freq': 8, 'min_child_samples': 29}. Best is trial 1 with value: 0.7163176253447335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's auc: 0.734284\tvalid_1's auc: 0.715567\n",
      "[0.83042581 0.47582315 0.70438927 ... 0.50726246 0.77859214 0.49504922]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's auc: 0.731466\tvalid_1's auc: 0.712934\n",
      "[0.75873496 0.53261449 0.74142908 ... 0.53916576 0.74246877 0.52355642]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's auc: 0.724755\tvalid_1's auc: 0.709129\n",
      "[0.72551212 0.5802728  0.72373744 ... 0.55810985 0.70598504 0.56764079]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's auc: 0.727767\tvalid_1's auc: 0.714895\n",
      "[0.81406188 0.47861366 0.7314254  ... 0.48647031 0.73148145 0.45542666]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's auc: 0.72184\tvalid_1's auc: 0.714706\n",
      "[0.73450374 0.55900766 0.70608854 ... 0.58047145 0.73573025 0.55748963]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's auc: 0.735879\tvalid_1's auc: 0.714346\n",
      "[0.77228093 0.55128509 0.742272   ... 0.50361788 0.76713915 0.52228516]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,099]\u001b[0m Trial 9 finished with value: 0.7139987337094849 and parameters: {'max_depth': 8, 'reg_alpha': 0.6165376994399163, 'reg_lambda': 0.06472855620684219, 'num_leaves': 17, 'colsample_bytree': 0.9636162709331701, 'subsample': 0.9275674951564696, 'subsample_freq': 3, 'min_child_samples': 39}. Best is trial 1 with value: 0.7163176253447335.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,122]\u001b[0m Trial 10 finished with value: 0.7135582648650771 and parameters: {'max_depth': 12, 'reg_alpha': 3.490951489540015e-05, 'reg_lambda': 9.4959473412392e-06, 'num_leaves': 8, 'colsample_bytree': 0.5246587990577197, 'subsample': 0.8126968918249768, 'subsample_freq': 1, 'min_child_samples': 60}. Best is trial 1 with value: 0.7163176253447335.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,173]\u001b[0m Trial 11 finished with value: 0.7164528892390798 and parameters: {'max_depth': 4, 'reg_alpha': 0.0031975314610893655, 'reg_lambda': 9.574610631029572, 'num_leaves': 11, 'colsample_bytree': 0.9784197155565215, 'subsample': 0.8401875857275422, 'subsample_freq': 1, 'min_child_samples': 53}. Best is trial 11 with value: 0.7164528892390798.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,218]\u001b[0m Trial 12 finished with value: 0.7170034752945893 and parameters: {'max_depth': 5, 'reg_alpha': 0.0014801622718582249, 'reg_lambda': 1.1581243248762921e-06, 'num_leaves': 9, 'colsample_bytree': 0.9947750888750357, 'subsample': 0.8422318297708964, 'subsample_freq': 1, 'min_child_samples': 60}. Best is trial 12 with value: 0.7170034752945893.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,273]\u001b[0m Trial 13 finished with value: 0.7162381664186829 and parameters: {'max_depth': 4, 'reg_alpha': 0.002991376156623131, 'reg_lambda': 1.0655489616903445e-08, 'num_leaves': 12, 'colsample_bytree': 0.9946795663074542, 'subsample': 0.8425217377597249, 'subsample_freq': 1, 'min_child_samples': 54}. Best is trial 12 with value: 0.7170034752945893.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's auc: 0.737183\tvalid_1's auc: 0.713999\n",
      "[0.79426351 0.50331505 0.72974655 ... 0.52680365 0.75626557 0.49257282]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's auc: 0.707395\tvalid_1's auc: 0.713558\n",
      "[0.73306736 0.5627712  0.7128773  ... 0.58915812 0.7364086  0.57019208]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's auc: 0.728709\tvalid_1's auc: 0.716453\n",
      "[0.82020111 0.47284013 0.72848744 ... 0.50011936 0.78502589 0.48279374]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's auc: 0.721084\tvalid_1's auc: 0.717003\n",
      "[0.80264232 0.49932617 0.7137365  ... 0.49010862 0.78663577 0.49021938]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's auc: 0.732424\tvalid_1's auc: 0.716238\n",
      "[0.83367633 0.47481644 0.72865127 ... 0.51342899 0.79063557 0.48637811]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,320]\u001b[0m Trial 14 finished with value: 0.7151861394237758 and parameters: {'max_depth': 6, 'reg_alpha': 0.0017307651643324175, 'reg_lambda': 3.509523029163789e-07, 'num_leaves': 8, 'colsample_bytree': 0.9415023516671401, 'subsample': 0.801916211976446, 'subsample_freq': 1, 'min_child_samples': 50}. Best is trial 12 with value: 0.7170034752945893.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,371]\u001b[0m Trial 15 finished with value: 0.7158368529121123 and parameters: {'max_depth': 6, 'reg_alpha': 0.021967310992905945, 'reg_lambda': 8.649143137867101, 'num_leaves': 12, 'colsample_bytree': 0.9301457355633047, 'subsample': 0.8420891228661368, 'subsample_freq': 8, 'min_child_samples': 64}. Best is trial 12 with value: 0.7170034752945893.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,418]\u001b[0m Trial 16 finished with value: 0.7181300237389282 and parameters: {'max_depth': 6, 'reg_alpha': 0.00023921019867912543, 'reg_lambda': 0.0003308993335188363, 'num_leaves': 11, 'colsample_bytree': 0.9004811994802815, 'subsample': 0.8460211836640904, 'subsample_freq': 2, 'min_child_samples': 48}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,462]\u001b[0m Trial 17 finished with value: 0.7159554671759999 and parameters: {'max_depth': 6, 'reg_alpha': 0.0002222470537142733, 'reg_lambda': 0.00013185832974984757, 'num_leaves': 8, 'colsample_bytree': 0.7637766427589645, 'subsample': 0.932000408300346, 'subsample_freq': 2, 'min_child_samples': 47}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's auc: 0.720985\tvalid_1's auc: 0.715186\n",
      "[0.81710681 0.49522248 0.75409046 ... 0.49003982 0.79292559 0.50120614]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's auc: 0.730886\tvalid_1's auc: 0.715837\n",
      "[0.82183349 0.49937286 0.74268347 ... 0.49555816 0.78054495 0.47353077]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.728454\tvalid_1's auc: 0.71813\n",
      "[0.81466493 0.50543793 0.71546603 ... 0.47522348 0.79269582 0.50090142]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's auc: 0.7186\tvalid_1's auc: 0.715955\n",
      "[0.80600748 0.49707381 0.70772253 ... 0.51623068 0.79629266 0.48261894]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-07 13:26:02,527]\u001b[0m Trial 18 finished with value: 0.7154275016529065 and parameters: {'max_depth': 7, 'reg_alpha': 6.948140256318918e-07, 'reg_lambda': 0.0012875214548336586, 'num_leaves': 13, 'colsample_bytree': 0.9013641932911393, 'subsample': 0.8019533922802823, 'subsample_freq': 4, 'min_child_samples': 64}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,574]\u001b[0m Trial 19 finished with value: 0.7155536943692787 and parameters: {'max_depth': 5, 'reg_alpha': 3.225548811211377e-08, 'reg_lambda': 1.4307598120186545e-06, 'num_leaves': 10, 'colsample_bytree': 0.9922859253647441, 'subsample': 0.9089460905419602, 'subsample_freq': 2, 'min_child_samples': 46}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,621]\u001b[0m Trial 20 finished with value: 0.7149745168793954 and parameters: {'max_depth': 9, 'reg_alpha': 0.00013056192341878513, 'reg_lambda': 5.637937081769047e-05, 'num_leaves': 9, 'colsample_bytree': 0.9012107459765035, 'subsample': 0.8560459676687561, 'subsample_freq': 7, 'min_child_samples': 58}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,668]\u001b[0m Trial 21 finished with value: 0.7152691579259933 and parameters: {'max_depth': 4, 'reg_alpha': 0.0009073378702238831, 'reg_lambda': 1.343060607245078, 'num_leaves': 11, 'colsample_bytree': 0.9834663378426245, 'subsample': 0.8269439985655633, 'subsample_freq': 1, 'min_child_samples': 53}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,715]\u001b[0m Trial 22 finished with value: 0.7151958995519757 and parameters: {'max_depth': 5, 'reg_alpha': 0.018210318852113876, 'reg_lambda': 0.010900687494414163, 'num_leaves': 13, 'colsample_bytree': 0.9271677004623541, 'subsample': 0.8276623268689965, 'subsample_freq': 1, 'min_child_samples': 55}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's auc: 0.744185\tvalid_1's auc: 0.715428\n",
      "[0.82643599 0.47205705 0.7342147  ... 0.49230504 0.78089204 0.46537417]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's auc: 0.725758\tvalid_1's auc: 0.715554\n",
      "[0.80908446 0.49627719 0.73215571 ... 0.48945803 0.80495616 0.48240626]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's auc: 0.723666\tvalid_1's auc: 0.714975\n",
      "[0.80777466 0.51187237 0.72552889 ... 0.53139932 0.79736628 0.48943284]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.727891\tvalid_1's auc: 0.715269\n",
      "[0.81474135 0.48723554 0.71180852 ... 0.51043179 0.78554579 0.49986798]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's auc: 0.731017\tvalid_1's auc: 0.715196\n",
      "[0.80877076 0.50354652 0.75804175 ... 0.48790536 0.77117552 0.48123034]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,762]\u001b[0m Trial 23 finished with value: 0.7172378331964235 and parameters: {'max_depth': 7, 'reg_alpha': 9.483801980082614e-06, 'reg_lambda': 8.165295546743551e-08, 'num_leaves': 10, 'colsample_bytree': 0.9989038858182858, 'subsample': 0.8453520628050639, 'subsample_freq': 2, 'min_child_samples': 45}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,807]\u001b[0m Trial 24 finished with value: 0.715408211046582 and parameters: {'max_depth': 7, 'reg_alpha': 5.856272291816531e-06, 'reg_lambda': 5.8940416375875705e-08, 'num_leaves': 9, 'colsample_bytree': 0.807663720099176, 'subsample': 0.8096040751114981, 'subsample_freq': 3, 'min_child_samples': 45}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,844]\u001b[0m Trial 25 finished with value: 0.7132715467460765 and parameters: {'max_depth': 8, 'reg_alpha': 7.07369898357578e-06, 'reg_lambda': 1.0319448678556543e-06, 'num_leaves': 14, 'colsample_bytree': 0.8972046680590269, 'subsample': 0.8564963817182438, 'subsample_freq': 2, 'min_child_samples': 49}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,879]\u001b[0m Trial 26 finished with value: 0.7142667353473492 and parameters: {'max_depth': 7, 'reg_alpha': 4.610359886205623e-05, 'reg_lambda': 1.3200456638212221e-08, 'num_leaves': 10, 'colsample_bytree': 0.9966907586276488, 'subsample': 0.859967624869128, 'subsample_freq': 4, 'min_child_samples': 45}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,921]\u001b[0m Trial 27 finished with value: 0.7166403985255547 and parameters: {'max_depth': 5, 'reg_alpha': 8.469142478443185e-07, 'reg_lambda': 3.0129816331816275e-06, 'num_leaves': 8, 'colsample_bytree': 0.9523928104170122, 'subsample': 0.8909126734252346, 'subsample_freq': 2, 'min_child_samples': 43}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,944]\u001b[0m Trial 28 finished with value: 0.7143262147168494 and parameters: {'max_depth': 10, 'reg_alpha': 0.0002847899102543592, 'reg_lambda': 1.2767562890794582e-07, 'num_leaves': 12, 'colsample_bytree': 0.7161436145185908, 'subsample': 0.8214732491586787, 'subsample_freq': 3, 'min_child_samples': 34}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's auc: 0.726071\tvalid_1's auc: 0.717238\n",
      "[0.80741783 0.5087894  0.71972897 ... 0.49555876 0.79245164 0.49083964]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.7227\tvalid_1's auc: 0.715408\n",
      "[0.80482783 0.48802603 0.73506332 ... 0.53008901 0.77975292 0.48805885]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's auc: 0.72556\tvalid_1's auc: 0.713272\n",
      "[0.78114926 0.53036919 0.75216636 ... 0.52324152 0.76378108 0.51441343]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's auc: 0.717115\tvalid_1's auc: 0.714267\n",
      "[0.78097111 0.51903552 0.73724961 ... 0.52282875 0.78490233 0.52149692]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's auc: 0.718181\tvalid_1's auc: 0.71664\n",
      "[0.79797171 0.49382048 0.72663854 ... 0.51579638 0.80373354 0.49486439]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's auc: 0.712538\tvalid_1's auc: 0.714326\n",
      "[0.72854057 0.58702879 0.72303451 ... 0.57682094 0.7318464  0.57353883]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:02,971]\u001b[0m Trial 29 finished with value: 0.711355461342888 and parameters: {'max_depth': 8, 'reg_alpha': 0.008304291680636691, 'reg_lambda': 0.0004250702503054764, 'num_leaves': 14, 'colsample_bytree': 0.8653440605457725, 'subsample': 0.8451374814161084, 'subsample_freq': 3, 'min_child_samples': 25}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,029]\u001b[0m Trial 30 finished with value: 0.7155034010027901 and parameters: {'max_depth': 6, 'reg_alpha': 0.0004418340393635789, 'reg_lambda': 0.00011004293965910129, 'num_leaves': 9, 'colsample_bytree': 0.8204812343615804, 'subsample': 0.8687861962019301, 'subsample_freq': 2, 'min_child_samples': 50}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,078]\u001b[0m Trial 31 finished with value: 0.715960289827581 and parameters: {'max_depth': 5, 'reg_alpha': 1.2497813030030418e-06, 'reg_lambda': 3.2875519951233938e-06, 'num_leaves': 11, 'colsample_bytree': 0.9539842187669709, 'subsample': 0.9139683422362228, 'subsample_freq': 2, 'min_child_samples': 42}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,119]\u001b[0m Trial 32 finished with value: 0.7172356515207085 and parameters: {'max_depth': 5, 'reg_alpha': 4.488205586152493e-08, 'reg_lambda': 3.132265095893337e-05, 'num_leaves': 8, 'colsample_bytree': 0.9989391617299548, 'subsample': 0.8889024030381442, 'subsample_freq': 2, 'min_child_samples': 43}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,163]\u001b[0m Trial 33 finished with value: 0.7157978123993127 and parameters: {'max_depth': 7, 'reg_alpha': 4.444676527426804e-05, 'reg_lambda': 3.525197035331554e-05, 'num_leaves': 9, 'colsample_bytree': 0.9155348935593003, 'subsample': 0.8899880950894279, 'subsample_freq': 3, 'min_child_samples': 34}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's auc: 0.714612\tvalid_1's auc: 0.711355\n",
      "[0.73289409 0.5569766  0.73658904 ... 0.58411203 0.73658904 0.56316925]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's auc: 0.730796\tvalid_1's auc: 0.715503\n",
      "[0.83249207 0.48657214 0.73286769 ... 0.49595767 0.81146064 0.47231534]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's auc: 0.729481\tvalid_1's auc: 0.71596\n",
      "[0.81039684 0.49511273 0.72483116 ... 0.5043006  0.80009171 0.48561118]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's auc: 0.715971\tvalid_1's auc: 0.717236\n",
      "[0.7971883  0.50786734 0.7312875  ... 0.51591015 0.78623732 0.48820791]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's auc: 0.72148\tvalid_1's auc: 0.715798\n",
      "[0.80443839 0.49931526 0.73725676 ... 0.52706627 0.77298973 0.4743356 ]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,209]\u001b[0m Trial 34 finished with value: 0.7150754480874857 and parameters: {'max_depth': 5, 'reg_alpha': 2.4196101980811626e-08, 'reg_lambda': 4.791169283404566e-07, 'num_leaves': 10, 'colsample_bytree': 0.9669422089842286, 'subsample': 0.872957865471637, 'subsample_freq': 1, 'min_child_samples': 58}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,252]\u001b[0m Trial 35 finished with value: 0.7165152392345212 and parameters: {'max_depth': 6, 'reg_alpha': 1.1606002955963982e-07, 'reg_lambda': 8.996638855736314e-06, 'num_leaves': 8, 'colsample_bytree': 0.9951832493393038, 'subsample': 0.8507102415166008, 'subsample_freq': 3, 'min_child_samples': 37}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,299]\u001b[0m Trial 36 finished with value: 0.7152890226575062 and parameters: {'max_depth': 4, 'reg_alpha': 1.0970986669950044e-08, 'reg_lambda': 0.0028765545177341168, 'num_leaves': 11, 'colsample_bytree': 0.8769039420933564, 'subsample': 0.83386466447127, 'subsample_freq': 2, 'min_child_samples': 18}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,345]\u001b[0m Trial 37 finished with value: 0.7162347216675535 and parameters: {'max_depth': 9, 'reg_alpha': 1.819264918303187e-05, 'reg_lambda': 0.00025484745052402243, 'num_leaves': 10, 'colsample_bytree': 0.9972202042372096, 'subsample': 0.884153008409129, 'subsample_freq': 4, 'min_child_samples': 42}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's auc: 0.72572\tvalid_1's auc: 0.715075\n",
      "[0.80305985 0.49722636 0.71389469 ... 0.50790887 0.79749213 0.49442771]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's auc: 0.7192\tvalid_1's auc: 0.716515\n",
      "[0.81004803 0.50326042 0.7406563  ... 0.52906939 0.78467553 0.49412316]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's auc: 0.729434\tvalid_1's auc: 0.715289\n",
      "[0.82038226 0.49637734 0.73379397 ... 0.51236513 0.79442922 0.49279777]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's auc: 0.722599\tvalid_1's auc: 0.716235\n",
      "[0.80108667 0.50019932 0.74079558 ... 0.51122428 0.79743013 0.49562871]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-07 13:26:03,391]\u001b[0m Trial 38 finished with value: 0.7145961683803539 and parameters: {'max_depth': 5, 'reg_alpha': 0.09927214596312421, 'reg_lambda': 1.3630537399505035e-07, 'num_leaves': 13, 'colsample_bytree': 0.9372812216020742, 'subsample': 0.9375094062458682, 'subsample_freq': 1, 'min_child_samples': 51}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,455]\u001b[0m Trial 39 finished with value: 0.7136044245302106 and parameters: {'max_depth': 10, 'reg_alpha': 0.00012941644407830512, 'reg_lambda': 1.910390307293699e-05, 'num_leaves': 18, 'colsample_bytree': 0.7631524154703024, 'subsample': 0.8674540983036397, 'subsample_freq': 5, 'min_child_samples': 48}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,491]\u001b[0m Trial 40 finished with value: 0.7120659986758376 and parameters: {'max_depth': 8, 'reg_alpha': 0.0008797331761715511, 'reg_lambda': 2.9584780574990475e-08, 'num_leaves': 15, 'colsample_bytree': 0.8281046694990203, 'subsample': 0.9509886084763555, 'subsample_freq': 2, 'min_child_samples': 32}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,546]\u001b[0m Trial 41 finished with value: 0.7166581964063896 and parameters: {'max_depth': 5, 'reg_alpha': 1.0961341920016177e-06, 'reg_lambda': 3.0638452864815352e-06, 'num_leaves': 8, 'colsample_bytree': 0.9619619161062235, 'subsample': 0.8942672097842392, 'subsample_freq': 2, 'min_child_samples': 44}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's auc: 0.724347\tvalid_1's auc: 0.714596\n",
      "[0.78329198 0.50974583 0.71211151 ... 0.53782864 0.75981552 0.48690989]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's auc: 0.752\tvalid_1's auc: 0.713604\n",
      "[0.81514451 0.51562516 0.71726725 ... 0.44388102 0.77012998 0.46480895]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's auc: 0.724599\tvalid_1's auc: 0.712066\n",
      "[0.76837394 0.53763108 0.73163366 ... 0.53116956 0.75603627 0.52045399]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's auc: 0.725794\tvalid_1's auc: 0.716658\n",
      "[0.82185211 0.47912237 0.73257704 ... 0.5060886  0.81329767 0.49078336]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's auc: 0.722975\tvalid_1's auc: 0.716503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,591]\u001b[0m Trial 42 finished with value: 0.716503297430606 and parameters: {'max_depth': 4, 'reg_alpha': 2.476061700009907e-07, 'reg_lambda': 9.782639028010576e-07, 'num_leaves': 9, 'colsample_bytree': 0.9676813317038017, 'subsample': 0.8998739815595164, 'subsample_freq': 2, 'min_child_samples': 44}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,631]\u001b[0m Trial 43 finished with value: 0.7165135168589565 and parameters: {'max_depth': 7, 'reg_alpha': 2.6021882387695207e-06, 'reg_lambda': 2.9263976972792634e-06, 'num_leaves': 8, 'colsample_bytree': 0.9623433489413962, 'subsample': 0.9160466927465782, 'subsample_freq': 2, 'min_child_samples': 38}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,659]\u001b[0m Trial 44 finished with value: 0.7127326728444068 and parameters: {'max_depth': 6, 'reg_alpha': 1.4261400731035633e-05, 'reg_lambda': 1.0244384775589458e-05, 'num_leaves': 20, 'colsample_bytree': 0.6519224879905657, 'subsample': 0.8986770810819061, 'subsample_freq': 1, 'min_child_samples': 61}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,708]\u001b[0m Trial 45 finished with value: 0.7161320680838986 and parameters: {'max_depth': 12, 'reg_alpha': 6.38864545540177e-08, 'reg_lambda': 4.792161844221924e-05, 'num_leaves': 10, 'colsample_bytree': 0.8794629570712952, 'subsample': 0.816050246301074, 'subsample_freq': 1, 'min_child_samples': 40}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,753]\u001b[0m Trial 46 finished with value: 0.7172672284060609 and parameters: {'max_depth': 13, 'reg_alpha': 4.933421619389069e-07, 'reg_lambda': 2.0408769099721616e-07, 'num_leaves': 9, 'colsample_bytree': 0.9985819699137978, 'subsample': 0.8349756883857732, 'subsample_freq': 3, 'min_child_samples': 56}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,778]\u001b[0m Trial 47 finished with value: 0.7113377782870907 and parameters: {'max_depth': 13, 'reg_alpha': 3.4749601888318094e-07, 'reg_lambda': 6.416030364471631e-08, 'num_leaves': 12, 'colsample_bytree': 0.9192919960305328, 'subsample': 0.8347940083862587, 'subsample_freq': 3, 'min_child_samples': 58}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8077984  0.50246846 0.72328152 ... 0.51242798 0.8057042  0.49521663]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's auc: 0.71537\tvalid_1's auc: 0.716514\n",
      "[0.79611847 0.50034909 0.73303434 ... 0.52264423 0.79087469 0.50246832]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's auc: 0.724856\tvalid_1's auc: 0.712733\n",
      "[0.73352159 0.58486008 0.70632466 ... 0.59738904 0.70512944 0.58617502]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's auc: 0.726391\tvalid_1's auc: 0.716132\n",
      "[0.80420659 0.48508833 0.71517946 ... 0.48501383 0.78348063 0.48811752]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.722241\tvalid_1's auc: 0.717267\n",
      "[0.81056971 0.47587862 0.74574941 ... 0.49779581 0.78369566 0.4868966 ]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's auc: 0.711853\tvalid_1's auc: 0.711338\n",
      "[0.73219331 0.56764463 0.73653546 ... 0.57399572 0.73653546 0.56399112]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,830]\u001b[0m Trial 48 finished with value: 0.716064550961763 and parameters: {'max_depth': 15, 'reg_alpha': 3.112591151122018e-06, 'reg_lambda': 4.1306953112646014e-07, 'num_leaves': 9, 'colsample_bytree': 0.9984829774995293, 'subsample': 0.8508490500756835, 'subsample_freq': 3, 'min_child_samples': 56}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,876]\u001b[0m Trial 49 finished with value: 0.7138442940338519 and parameters: {'max_depth': 14, 'reg_alpha': 1.0705320941467742e-08, 'reg_lambda': 2.0338506509864646e-08, 'num_leaves': 23, 'colsample_bytree': 0.5615486044366665, 'subsample': 0.8822598534859313, 'subsample_freq': 4, 'min_child_samples': 62}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,939]\u001b[0m Trial 50 finished with value: 0.7146089139595324 and parameters: {'max_depth': 11, 'reg_alpha': 8.3926263528373e-05, 'reg_lambda': 0.004258549750417328, 'num_leaves': 11, 'colsample_bytree': 0.8393917009818934, 'subsample': 0.83242695863175, 'subsample_freq': 3, 'min_child_samples': 52}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:03,985]\u001b[0m Trial 51 finished with value: 0.7159098816360547 and parameters: {'max_depth': 5, 'reg_alpha': 7.572228907151893e-08, 'reg_lambda': 1.6114028110725807e-07, 'num_leaves': 8, 'colsample_bytree': 0.9733718111387432, 'subsample': 0.8638623643056708, 'subsample_freq': 2, 'min_child_samples': 47}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.722675\tvalid_1's auc: 0.716065\n",
      "[0.80590764 0.50377369 0.72286739 ... 0.50969176 0.78327495 0.48622498]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's auc: 0.737196\tvalid_1's auc: 0.713844\n",
      "[0.77047366 0.55001238 0.73411433 ... 0.55444592 0.75903223 0.52518455]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's auc: 0.726929\tvalid_1's auc: 0.714609\n",
      "[0.80634378 0.49948937 0.74651139 ... 0.49456154 0.76265426 0.49214149]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's auc: 0.719896\tvalid_1's auc: 0.71591\n",
      "[0.8081283  0.48827926 0.7357848  ... 0.51065672 0.80299081 0.48724584]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:04,035]\u001b[0m Trial 52 finished with value: 0.7149307685400526 and parameters: {'max_depth': 6, 'reg_alpha': 1.5721916217458298e-06, 'reg_lambda': 1.3566192037877059e-06, 'num_leaves': 10, 'colsample_bytree': 0.9449733518420658, 'subsample': 0.9932644553585325, 'subsample_freq': 1, 'min_child_samples': 41}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:04,079]\u001b[0m Trial 53 finished with value: 0.7162232391637889 and parameters: {'max_depth': 13, 'reg_alpha': 5.04680994451485e-07, 'reg_lambda': 5.951697018162487e-07, 'num_leaves': 9, 'colsample_bytree': 0.9817662995512603, 'subsample': 0.8744344921451103, 'subsample_freq': 2, 'min_child_samples': 56}. Best is trial 16 with value: 0.7181300237389282.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:04,123]\u001b[0m Trial 54 finished with value: 0.7183035243708105 and parameters: {'max_depth': 4, 'reg_alpha': 1.1368236970200307e-05, 'reg_lambda': 4.6208018285505224e-06, 'num_leaves': 8, 'colsample_bytree': 0.9476860631912927, 'subsample': 0.8466146128214767, 'subsample_freq': 2, 'min_child_samples': 48}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:04,202]\u001b[0m Trial 55 finished with value: 0.7147357956261305 and parameters: {'max_depth': 4, 'reg_alpha': 1.5482440707398206e-05, 'reg_lambda': 2.030028516466621e-05, 'num_leaves': 10, 'colsample_bytree': 0.9145362348831545, 'subsample': 0.8513091490592402, 'subsample_freq': 1, 'min_child_samples': 48}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's auc: 0.727454\tvalid_1's auc: 0.714931\n",
      "[0.80905334 0.48858891 0.75475197 ... 0.5156889  0.79905865 0.49196624]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's auc: 0.722391\tvalid_1's auc: 0.716223\n",
      "[0.80150426 0.50925626 0.75501481 ... 0.51984668 0.78884135 0.49705744]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.71943\tvalid_1's auc: 0.718304\n",
      "[0.81396622 0.48484708 0.73012599 ... 0.50605475 0.79710943 0.49467651]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's auc: 0.726192\tvalid_1's auc: 0.714736\n",
      "[0.81720721 0.48406399 0.73488491 ... 0.51735189 0.77361985 0.49083981]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:04,282]\u001b[0m Trial 56 finished with value: 0.7164915852767663 and parameters: {'max_depth': 4, 'reg_alpha': 0.0011828142766089579, 'reg_lambda': 0.00048323087880371726, 'num_leaves': 11, 'colsample_bytree': 0.9454861400889778, 'subsample': 0.8401700690907752, 'subsample_freq': 2, 'min_child_samples': 52}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:04,329]\u001b[0m Trial 57 finished with value: 0.714262257170881 and parameters: {'max_depth': 11, 'reg_alpha': 9.277868611525791e-06, 'reg_lambda': 0.00012905441074298712, 'num_leaves': 9, 'colsample_bytree': 0.9830745252833989, 'subsample': 0.8232575603817907, 'subsample_freq': 3, 'min_child_samples': 46}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:04,376]\u001b[0m Trial 58 finished with value: 0.7157585422364381 and parameters: {'max_depth': 7, 'reg_alpha': 0.008552972020532033, 'reg_lambda': 7.219730652657244e-06, 'num_leaves': 8, 'colsample_bytree': 0.8921194771206999, 'subsample': 0.8121338810211703, 'subsample_freq': 1, 'min_child_samples': 63}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:04,427]\u001b[0m Trial 59 finished with value: 0.7173177514226248 and parameters: {'max_depth': 4, 'reg_alpha': 0.00042720589476334924, 'reg_lambda': 0.0011775490385909336, 'num_leaves': 12, 'colsample_bytree': 0.9980929113775638, 'subsample': 0.8457400602101588, 'subsample_freq': 2, 'min_child_samples': 54}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's auc: 0.741264\tvalid_1's auc: 0.716492\n",
      "[0.85720324 0.45905956 0.73908393 ... 0.47400072 0.84199705 0.48770847]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's auc: 0.721552\tvalid_1's auc: 0.714262\n",
      "[0.80453932 0.4738399  0.73331907 ... 0.50542007 0.78527829 0.48356259]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's auc: 0.720599\tvalid_1's auc: 0.715759\n",
      "[0.80840538 0.48104246 0.75171475 ... 0.50106829 0.78738062 0.4812823 ]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's auc: 0.730503\tvalid_1's auc: 0.717318\n",
      "[0.83020465 0.48058569 0.70411089 ... 0.50298287 0.79436896 0.50124095]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:04,454]\u001b[0m Trial 60 finished with value: 0.7157684171896755 and parameters: {'max_depth': 14, 'reg_alpha': 0.00047457697134114526, 'reg_lambda': 0.028181249798281956, 'num_leaves': 12, 'colsample_bytree': 0.9996480050521642, 'subsample': 0.8463324061421365, 'subsample_freq': 3, 'min_child_samples': 50}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:04,513]\u001b[0m Trial 61 finished with value: 0.7176756610649655 and parameters: {'max_depth': 4, 'reg_alpha': 0.003281541062887751, 'reg_lambda': 0.0013831312275458085, 'num_leaves': 9, 'colsample_bytree': 0.9761036792778879, 'subsample': 0.8578111053568273, 'subsample_freq': 2, 'min_child_samples': 54}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:04,565]\u001b[0m Trial 62 finished with value: 0.7160163244459519 and parameters: {'max_depth': 4, 'reg_alpha': 0.005019120865353783, 'reg_lambda': 0.0009684519304732687, 'num_leaves': 11, 'colsample_bytree': 0.9336710911904298, 'subsample': 0.8591981871911168, 'subsample_freq': 2, 'min_child_samples': 55}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:04,611]\u001b[0m Trial 63 finished with value: 0.7178589218250475 and parameters: {'max_depth': 5, 'reg_alpha': 0.002390937129136813, 'reg_lambda': 0.0017059786323479133, 'num_leaves': 9, 'colsample_bytree': 0.9780670968066796, 'subsample': 0.8338912094029933, 'subsample_freq': 2, 'min_child_samples': 54}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's auc: 0.71152\tvalid_1's auc: 0.715768\n",
      "[0.73887483 0.57362105 0.72990628 ... 0.56599174 0.74460932 0.55094625]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's auc: 0.729443\tvalid_1's auc: 0.717676\n",
      "[0.83595586 0.47070882 0.70601607 ... 0.50788345 0.80072346 0.47252568]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's auc: 0.729679\tvalid_1's auc: 0.716016\n",
      "[0.83181531 0.47125106 0.72743923 ... 0.50425289 0.79385807 0.49452113]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's auc: 0.722939\tvalid_1's auc: 0.717859\n",
      "[0.80995146 0.5123797  0.73290545 ... 0.49066261 0.79280082 0.49528466]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-07 13:26:04,669]\u001b[0m Trial 64 finished with value: 0.7178884318597224 and parameters: {'max_depth': 4, 'reg_alpha': 0.023843874519243285, 'reg_lambda': 0.001911817736332933, 'num_leaves': 10, 'colsample_bytree': 0.9771462251216064, 'subsample': 0.8362501236527988, 'subsample_freq': 2, 'min_child_samples': 54}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:04,733]\u001b[0m Trial 65 finished with value: 0.7165468161198736 and parameters: {'max_depth': 4, 'reg_alpha': 0.04025139217205023, 'reg_lambda': 0.0026066754006131786, 'num_leaves': 12, 'colsample_bytree': 0.9515656073141204, 'subsample': 0.836257023579055, 'subsample_freq': 2, 'min_child_samples': 54}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:04,763]\u001b[0m Trial 66 finished with value: 0.7137751693611893 and parameters: {'max_depth': 4, 'reg_alpha': 0.0019964884036352795, 'reg_lambda': 0.006506134465102988, 'num_leaves': 10, 'colsample_bytree': 0.9770901972457849, 'subsample': 0.827453774179952, 'subsample_freq': 6, 'min_child_samples': 59}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:04,792]\u001b[0m Trial 67 finished with value: 0.7140625764304156 and parameters: {'max_depth': 4, 'reg_alpha': 0.24685247485377618, 'reg_lambda': 0.020505501324481545, 'num_leaves': 9, 'colsample_bytree': 0.9223098295761463, 'subsample': 0.8062755860266567, 'subsample_freq': 2, 'min_child_samples': 56}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:04,841]\u001b[0m Trial 68 finished with value: 0.7149188267361374 and parameters: {'max_depth': 5, 'reg_alpha': 2.3284182325722944, 'reg_lambda': 0.0014590835433882414, 'num_leaves': 13, 'colsample_bytree': 0.9077026827389975, 'subsample': 0.8171241809885994, 'subsample_freq': 3, 'min_child_samples': 53}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's auc: 0.728728\tvalid_1's auc: 0.717888\n",
      "[0.83176389 0.46203554 0.7163805  ... 0.50414456 0.81287197 0.48307697]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's auc: 0.735759\tvalid_1's auc: 0.716547\n",
      "[0.83731496 0.4779495  0.71431577 ... 0.50392082 0.82050153 0.48364348]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's auc: 0.714089\tvalid_1's auc: 0.713775\n",
      "[0.76540534 0.51509567 0.72889532 ... 0.52279149 0.75840471 0.52297782]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's auc: 0.71369\tvalid_1's auc: 0.714063\n",
      "[0.76880249 0.53508457 0.74189994 ... 0.53941101 0.75675926 0.53796836]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's auc: 0.730958\tvalid_1's auc: 0.714919\n",
      "[0.81848251 0.49629757 0.75012465 ... 0.48299792 0.7665465  0.47728119]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:04,904]\u001b[0m Trial 69 finished with value: 0.7158326043857193 and parameters: {'max_depth': 6, 'reg_alpha': 0.008678602857905806, 'reg_lambda': 0.1510189900007604, 'num_leaves': 14, 'colsample_bytree': 0.9786630418762338, 'subsample': 0.8544272281265091, 'subsample_freq': 3, 'min_child_samples': 57}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:04,961]\u001b[0m Trial 70 finished with value: 0.7136724009524966 and parameters: {'max_depth': 4, 'reg_alpha': 0.01993735573948337, 'reg_lambda': 0.00023143785479258326, 'num_leaves': 16, 'colsample_bytree': 0.7851503401757419, 'subsample': 0.8298956709002615, 'subsample_freq': 2, 'min_child_samples': 54}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:05,017]\u001b[0m Trial 71 finished with value: 0.7172752661586961 and parameters: {'max_depth': 5, 'reg_alpha': 0.004604167118297965, 'reg_lambda': 0.0006660949130229948, 'num_leaves': 11, 'colsample_bytree': 0.9601011514028647, 'subsample': 0.8452587702127219, 'subsample_freq': 2, 'min_child_samples': 49}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:05,065]\u001b[0m Trial 72 finished with value: 0.7165356780912221 and parameters: {'max_depth': 5, 'reg_alpha': 0.0038045716157382365, 'reg_lambda': 0.0016514409081574428, 'num_leaves': 11, 'colsample_bytree': 0.9339149029244966, 'subsample': 0.8411124157811812, 'subsample_freq': 2, 'min_child_samples': 50}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's auc: 0.742377\tvalid_1's auc: 0.715833\n",
      "[0.82443126 0.48506807 0.73299294 ... 0.50580199 0.77040798 0.44708779]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's auc: 0.717092\tvalid_1's auc: 0.713672\n",
      "[0.72329597 0.60243819 0.70397955 ... 0.60847371 0.70398545 0.59470835]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's auc: 0.729055\tvalid_1's auc: 0.717275\n",
      "[0.82166943 0.49279597 0.73174162 ... 0.50139929 0.78696568 0.49511939]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's auc: 0.72911\tvalid_1's auc: 0.716536\n",
      "[0.81507359 0.49638884 0.73691502 ... 0.49704227 0.80352705 0.50302031]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:05,114]\u001b[0m Trial 73 finished with value: 0.7165510646462666 and parameters: {'max_depth': 5, 'reg_alpha': 0.03534862065252245, 'reg_lambda': 0.0005561606603763867, 'num_leaves': 10, 'colsample_bytree': 0.9569211499947462, 'subsample': 0.8225413057726885, 'subsample_freq': 2, 'min_child_samples': 52}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:05,165]\u001b[0m Trial 74 finished with value: 0.716357584457834 and parameters: {'max_depth': 6, 'reg_alpha': 0.0028494712030904777, 'reg_lambda': 0.010248126395211941, 'num_leaves': 11, 'colsample_bytree': 0.9852854629814685, 'subsample': 0.8470491464980582, 'subsample_freq': 1, 'min_child_samples': 49}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:05,223]\u001b[0m Trial 75 finished with value: 0.7180951169274841 and parameters: {'max_depth': 4, 'reg_alpha': 0.0006139737300783603, 'reg_lambda': 0.0007253007973603372, 'num_leaves': 9, 'colsample_bytree': 0.9676073333698263, 'subsample': 0.8369629017275072, 'subsample_freq': 2, 'min_child_samples': 51}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:05,247]\u001b[0m Trial 76 finished with value: 0.7099404724039838 and parameters: {'max_depth': 4, 'reg_alpha': 0.0006835863672598803, 'reg_lambda': 0.0007366417116299716, 'num_leaves': 12, 'colsample_bytree': 0.9438218940347725, 'subsample': 0.8634645382785542, 'subsample_freq': 2, 'min_child_samples': 51}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:05,310]\u001b[0m Trial 77 finished with value: 0.7173114360455544 and parameters: {'max_depth': 5, 'reg_alpha': 0.0003139343239733408, 'reg_lambda': 0.0002558881601605841, 'num_leaves': 10, 'colsample_bytree': 0.9680206268552294, 'subsample': 0.8394018472935756, 'subsample_freq': 2, 'min_child_samples': 48}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's auc: 0.725584\tvalid_1's auc: 0.716551\n",
      "[0.8124421  0.51608947 0.74377854 ... 0.48201018 0.79303477 0.50237439]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's auc: 0.730241\tvalid_1's auc: 0.716358\n",
      "[0.81124761 0.51201134 0.70189038 ... 0.51130102 0.79154709 0.48660069]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's auc: 0.728104\tvalid_1's auc: 0.718095\n",
      "[0.83467081 0.45357332 0.71570539 ... 0.50068798 0.83492659 0.47047274]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.71545\tvalid_1's auc: 0.70994\n",
      "[0.73226957 0.57385046 0.71250981 ... 0.58655499 0.7070854  0.57254014]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's auc: 0.725584\tvalid_1's auc: 0.717311\n",
      "[0.81383181 0.48803056 0.74216163 ... 0.48598033 0.79868452 0.48142451]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:05,355]\u001b[0m Trial 78 finished with value: 0.7149854252579716 and parameters: {'max_depth': 4, 'reg_alpha': 0.0001551872648691529, 'reg_lambda': 0.00019371549856812644, 'num_leaves': 9, 'colsample_bytree': 0.8891376262347808, 'subsample': 0.856032492555518, 'subsample_freq': 1, 'min_child_samples': 47}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:05,404]\u001b[0m Trial 79 finished with value: 0.7157913821972046 and parameters: {'max_depth': 5, 'reg_alpha': 0.0002441343416434693, 'reg_lambda': 8.429017065703055e-05, 'num_leaves': 10, 'colsample_bytree': 0.9683467017076799, 'subsample': 0.8385260249280078, 'subsample_freq': 2, 'min_child_samples': 54}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:05,452]\u001b[0m Trial 80 finished with value: 0.717252301151167 and parameters: {'max_depth': 4, 'reg_alpha': 0.00044686606502936213, 'reg_lambda': 0.0023887698271892925, 'num_leaves': 8, 'colsample_bytree': 0.9314328000952798, 'subsample': 0.8218191156058066, 'subsample_freq': 2, 'min_child_samples': 52}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:05,504]\u001b[0m Trial 81 finished with value: 0.7169325134213246 and parameters: {'max_depth': 5, 'reg_alpha': 0.0017286587527773132, 'reg_lambda': 0.006208198916678702, 'num_leaves': 10, 'colsample_bytree': 0.9554463648035507, 'subsample': 0.8475557869336089, 'subsample_freq': 2, 'min_child_samples': 49}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's auc: 0.719521\tvalid_1's auc: 0.714985\n",
      "[0.80506568 0.4945094  0.7167675  ... 0.51638202 0.79710796 0.50569794]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's auc: 0.726917\tvalid_1's auc: 0.715791\n",
      "[0.8178176  0.48501658 0.74129995 ... 0.49595693 0.79850885 0.49462032]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's auc: 0.718484\tvalid_1's auc: 0.717252\n",
      "[0.80502417 0.49839729 0.72268257 ... 0.50839055 0.80532564 0.50058596]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's auc: 0.726975\tvalid_1's auc: 0.716933\n",
      "[0.81516065 0.49030692 0.73569492 ... 0.50653232 0.7954836  0.48042986]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-07 13:26:05,554]\u001b[0m Trial 82 finished with value: 0.7169652385570535 and parameters: {'max_depth': 6, 'reg_alpha': 0.007941298998130926, 'reg_lambda': 0.00038136774710255655, 'num_leaves': 11, 'colsample_bytree': 0.967639100638866, 'subsample': 0.8296678993214491, 'subsample_freq': 2, 'min_child_samples': 48}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:05,605]\u001b[0m Trial 83 finished with value: 0.7168476577185046 and parameters: {'max_depth': 5, 'reg_alpha': 6.617174868786636e-05, 'reg_lambda': 0.0009592952539824358, 'num_leaves': 12, 'colsample_bytree': 0.9883193416125359, 'subsample': 0.8425793407154427, 'subsample_freq': 2, 'min_child_samples': 51}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:05,644]\u001b[0m Trial 84 finished with value: 0.714082900462079 and parameters: {'max_depth': 4, 'reg_alpha': 0.014495914933892054, 'reg_lambda': 0.01753055252486331, 'num_leaves': 9, 'colsample_bytree': 0.956279938555071, 'subsample': 0.867434469589626, 'subsample_freq': 1, 'min_child_samples': 46}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:05,673]\u001b[0m Trial 85 finished with value: 0.7136138401832975 and parameters: {'max_depth': 5, 'reg_alpha': 0.0007703920051540864, 'reg_lambda': 0.0017982976626586885, 'num_leaves': 11, 'colsample_bytree': 0.9082489168377922, 'subsample': 0.8511907287763341, 'subsample_freq': 3, 'min_child_samples': 54}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's auc: 0.727563\tvalid_1's auc: 0.716965\n",
      "[0.81394586 0.50624218 0.7222858  ... 0.46918252 0.7927639  0.47946914]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's auc: 0.732476\tvalid_1's auc: 0.716848\n",
      "[0.82327229 0.47737255 0.73020172 ... 0.47617799 0.81180889 0.50274216]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.71824\tvalid_1's auc: 0.714083\n",
      "[0.79548082 0.50081716 0.71923435 ... 0.50709229 0.77013096 0.51514448]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's auc: 0.71449\tvalid_1's auc: 0.713614\n",
      "[0.74461536 0.56930086 0.74417577 ... 0.58861824 0.74347653 0.53660126]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's auc: 0.740966\tvalid_1's auc: 0.71518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-07 13:26:05,754]\u001b[0m Trial 86 finished with value: 0.7151803981718936 and parameters: {'max_depth': 4, 'reg_alpha': 0.0022675561999371064, 'reg_lambda': 7.439120235991442e-05, 'num_leaves': 13, 'colsample_bytree': 0.9257956971692288, 'subsample': 0.8385730166616774, 'subsample_freq': 2, 'min_child_samples': 59}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:05,804]\u001b[0m Trial 87 finished with value: 0.7159483480236659 and parameters: {'max_depth': 5, 'reg_alpha': 0.0001566842105329193, 'reg_lambda': 0.0037022891631610425, 'num_leaves': 8, 'colsample_bytree': 0.976001622239429, 'subsample': 0.8161808990466414, 'subsample_freq': 1, 'min_child_samples': 49}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:05,860]\u001b[0m Trial 88 finished with value: 0.7171210561331383 and parameters: {'max_depth': 6, 'reg_alpha': 0.08382222457323028, 'reg_lambda': 0.0001704221711878511, 'num_leaves': 10, 'colsample_bytree': 0.9447005233742339, 'subsample': 0.8449190161980205, 'subsample_freq': 2, 'min_child_samples': 53}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:05,907]\u001b[0m Trial 89 finished with value: 0.716581378456205 and parameters: {'max_depth': 5, 'reg_alpha': 0.004837160384758672, 'reg_lambda': 0.0003083163582214951, 'num_leaves': 9, 'colsample_bytree': 0.8615417301196149, 'subsample': 0.8258065200008171, 'subsample_freq': 3, 'min_child_samples': 55}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84781288 0.46937121 0.72517746 ... 0.4789218  0.82283308 0.46793746]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's auc: 0.722038\tvalid_1's auc: 0.715948\n",
      "[0.80893364 0.47743953 0.72793482 ... 0.49844357 0.77498904 0.48575878]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's auc: 0.731492\tvalid_1's auc: 0.717121\n",
      "[0.82613581 0.48599008 0.74083222 ... 0.47151998 0.80183124 0.48363837]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.72347\tvalid_1's auc: 0.716581\n",
      "[0.80228388 0.48701626 0.71247762 ... 0.50512674 0.77570423 0.48024666]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:05,970]\u001b[0m Trial 90 finished with value: 0.7163736599631044 and parameters: {'max_depth': 4, 'reg_alpha': 2.5902463311319516e-05, 'reg_lambda': 0.0010053451167628832, 'num_leaves': 10, 'colsample_bytree': 0.9704362284562095, 'subsample': 0.8599884816165628, 'subsample_freq': 2, 'min_child_samples': 51}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:05,995]\u001b[0m Trial 91 finished with value: 0.7135540163386842 and parameters: {'max_depth': 4, 'reg_alpha': 0.0011962431748457683, 'reg_lambda': 0.0005881492706340524, 'num_leaves': 9, 'colsample_bytree': 0.9862337626035407, 'subsample': 0.8328623259721266, 'subsample_freq': 3, 'min_child_samples': 57}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:06,040]\u001b[0m Trial 92 finished with value: 0.7170185173745209 and parameters: {'max_depth': 16, 'reg_alpha': 0.000356884252019193, 'reg_lambda': 0.006387925437777251, 'num_leaves': 8, 'colsample_bytree': 0.9985109731727113, 'subsample': 0.8366429869423837, 'subsample_freq': 2, 'min_child_samples': 57}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:06,065]\u001b[0m Trial 93 finished with value: 0.7136391016915795 and parameters: {'max_depth': 5, 'reg_alpha': 8.190983565465502e-05, 'reg_lambda': 0.0003019340378291994, 'num_leaves': 9, 'colsample_bytree': 0.7172365517777091, 'subsample': 0.8322063129441681, 'subsample_freq': 3, 'min_child_samples': 55}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:06,119]\u001b[0m Trial 94 finished with value: 0.715881979151907 and parameters: {'max_depth': 4, 'reg_alpha': 0.000723926421694759, 'reg_lambda': 0.0020067217751217653, 'num_leaves': 11, 'colsample_bytree': 0.9996429876334776, 'subsample': 0.8511540455611115, 'subsample_freq': 2, 'min_child_samples': 53}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's auc: 0.733746\tvalid_1's auc: 0.716374\n",
      "[0.84182928 0.44766046 0.70413278 ... 0.49940353 0.82025168 0.46984752]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's auc: 0.709916\tvalid_1's auc: 0.713554\n",
      "[0.74096917 0.55935116 0.72723647 ... 0.56982209 0.73493809 0.56555349]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's auc: 0.719321\tvalid_1's auc: 0.717019\n",
      "[0.80484927 0.48802213 0.73543907 ... 0.51097978 0.79897183 0.4925368 ]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's auc: 0.707422\tvalid_1's auc: 0.713639\n",
      "[0.72824085 0.56963154 0.72401194 ... 0.56709161 0.73175917 0.57003012]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's auc: 0.729902\tvalid_1's auc: 0.715882\n",
      "[0.83106013 0.46773396 0.7124858  ... 0.51544261 0.78513224 0.4925259 ]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:06,182]\u001b[0m Trial 95 finished with value: 0.7155455417916059 and parameters: {'max_depth': 5, 'reg_alpha': 0.0013957363621028803, 'reg_lambda': 0.054395101000858, 'num_leaves': 10, 'colsample_bytree': 0.9616105609580528, 'subsample': 0.8189074168526016, 'subsample_freq': 2, 'min_child_samples': 60}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:06,231]\u001b[0m Trial 96 finished with value: 0.7163261223975192 and parameters: {'max_depth': 6, 'reg_alpha': 0.033655697871893764, 'reg_lambda': 0.003310030505429681, 'num_leaves': 9, 'colsample_bytree': 0.98850154248723, 'subsample': 0.8430631348704727, 'subsample_freq': 1, 'min_child_samples': 48}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:06,278]\u001b[0m Trial 97 finished with value: 0.7146398018946591 and parameters: {'max_depth': 9, 'reg_alpha': 0.005732856914645546, 'reg_lambda': 0.001231532418534422, 'num_leaves': 8, 'colsample_bytree': 0.9389033124197129, 'subsample': 0.853704866537162, 'subsample_freq': 2, 'min_child_samples': 50}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:06,317]\u001b[0m Trial 98 finished with value: 0.7142488226414765 and parameters: {'max_depth': 4, 'reg_alpha': 0.01327512516863212, 'reg_lambda': 0.0006365961381837356, 'num_leaves': 9, 'colsample_bytree': 0.9740604372948037, 'subsample': 0.8361361165523941, 'subsample_freq': 5, 'min_child_samples': 47}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n",
      "/home/bbok0525/anaconda3/envs/default/lib/python3.10/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2023-07-07 13:26:06,364]\u001b[0m Trial 99 finished with value: 0.7144867401194778 and parameters: {'max_depth': 6, 'reg_alpha': 0.0029937361894361958, 'reg_lambda': 0.00011398909347559027, 'num_leaves': 11, 'colsample_bytree': 0.9499130661623109, 'subsample': 0.8058632265448513, 'subsample_freq': 3, 'min_child_samples': 44}. Best is trial 54 with value: 0.7183035243708105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's auc: 0.734506\tvalid_1's auc: 0.715546\n",
      "[0.83428523 0.49349389 0.70776444 ... 0.4573396  0.79484549 0.47812764]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's auc: 0.721624\tvalid_1's auc: 0.716326\n",
      "[0.80331263 0.49848685 0.72259465 ... 0.50517502 0.78364308 0.49699655]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's auc: 0.720027\tvalid_1's auc: 0.71464\n",
      "[0.8064906  0.48326454 0.72238137 ... 0.51315311 0.80101358 0.48545206]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's auc: 0.718482\tvalid_1's auc: 0.714249\n",
      "[0.79913406 0.4983616  0.72180705 ... 0.48777779 0.76690483 0.48797247]\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's auc: 0.728267\tvalid_1's auc: 0.714487\n",
      "[0.80704174 0.47483163 0.76182652 ... 0.51422568 0.77451122 0.5125744 ]\n",
      "trial 100\n",
      "best_trail {'max_depth': 4, 'reg_alpha': 1.1368236970200307e-05, 'reg_lambda': 4.6208018285505224e-06, 'num_leaves': 8, 'colsample_bytree': 0.9476860631912927, 'subsample': 0.8466146128214767, 'subsample_freq': 2, 'min_child_samples': 48}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "print(\"trial\",len(study.trials))\n",
    "print('best_trail', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터\n",
    "# param1={\"num_leaves\":150,\n",
    "#         \"max_bin\":200,\n",
    "#        \"feature_fraction\":0.52,\n",
    "#        \"bagging_fraction\":0.52,\n",
    "#        \"objective\":\"binary\",\n",
    "#        \"learning_rate\":0.05,\n",
    "#        \"boosting_type\":\"gbdt\",\n",
    "#        \"metric\":\"auc\"\n",
    "#        }\n",
    "# param2={\"num_leaves\":100,\n",
    "#        \"max_bin\":200,\n",
    "#        \"feature_fraction\":0.52,\n",
    "#        \"bagging_fraction\":0.52,\n",
    "#        \"objective\":\"binary\",\n",
    "#        \"learning_rate\":0.05,\n",
    "       \n",
    "#        \"metric\":\"auc\"\n",
    "#        }\n",
    "\n",
    "param1 = {'max_depth': 5, \n",
    "          'reg_alpha': 3.0946424850432625e-06, \n",
    "          'reg_lambda': 4.1015307348324576e-06, \n",
    "          'num_leaves': 8, \n",
    "          'colsample_bytree': 0.6961655515441743,\n",
    "          'subsample': 0.8632170308194024, \n",
    "          'subsample_freq': 5,\n",
    "          'min_child_samples': 49,\n",
    "          \"metric\":\"auc\",\n",
    "          \"boosting_type\":\"gbdt\",\n",
    "          }\n",
    "param2 = {'max_depth': 6, \n",
    "          'reg_alpha': 1.6114208357018784e-08,\n",
    "          'reg_lambda': 0.00013461567148605243,\n",
    "          'num_leaves': 32,\n",
    "          'colsample_bytree': 0.7544537836898809,\n",
    "          'subsample': 0.8536948315468904,\n",
    "          'subsample_freq': 6,\n",
    "          'min_child_samples': 49,\n",
    "          \"metric\":\"auc\",\n",
    "          \"boosting_type\":\"gbdt\",\n",
    "          }\n",
    "param3 = {'max_depth': 4,\n",
    "          'reg_alpha': 0.0056688664725702215,\n",
    "          'reg_lambda': 1.0001169416586301e-07,\n",
    "          'num_leaves': 52,\n",
    "          'colsample_bytree': 0.7643558367967738,\n",
    "          'subsample': 0.903085447011872,\n",
    "          'subsample_freq': 7,\n",
    "          'min_child_samples': 48,\n",
    "          \"metric\":\"auc\",\n",
    "          \"boosting_type\":\"gbdt\",\n",
    "          }\n",
    "param4 = {'max_depth': 4,\n",
    "          'reg_alpha': 1.1368236970200307e-05, \n",
    "          'reg_lambda': 4.6208018285505224e-06, \n",
    "          'num_leaves': 8,\n",
    "          'colsample_bytree': 0.9476860631912927, \n",
    "          'subsample': 0.8466146128214767,\n",
    "          'subsample_freq': 2,\n",
    "          'min_child_samples': 48,\n",
    "          \"metric\":\"auc\",\n",
    "          \"boosting_type\":\"gbdt\",\n",
    "          }\n",
    "\n",
    "\n",
    "params = [param4, param2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.665030\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's auc: 0.718078\tvalid_1's auc: 0.71661\n",
      "1\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data: 10386, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.801464\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's auc: 0.724032\tvalid_1's auc: 0.577494\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "\n",
    "models = []\n",
    "for  i in range(2):\n",
    "    print(i)\n",
    "    train = lgbm.Dataset(x_train, y_train.iloc[:,i])\n",
    "    test = lgbm.Dataset(x_test, y_test.iloc[:,i])\n",
    "    model = lgbm.train(params=params[i], train_set=train, valid_sets=[train, test], num_boost_round=500, early_stopping_rounds=10, verbose_eval=100)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission[['id']]\n",
    "\n",
    "ec1 = pd.DataFrame(models[0].predict(test_df), columns=['EC1'])\n",
    "ec2 = pd.DataFrame(models[1].predict(test_df), columns=['EC2'])\n",
    "submission = pd.concat([submission, ec1, ec2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission.to_csv('submit_04_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
